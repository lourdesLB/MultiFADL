{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from src.MonoFADLModel import MonoFADLModel\n",
    "from src.MultiFADLModelOvR import MultiFADLModelOvR\n",
    "from src.NoSelectionModel import NoSelectionModel\n",
    "\n",
    "# Seed for neural network executions\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results = pd.DataFrame(columns=['Accuracy', 'Number of selected features', 'Selected Features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.498150</td>\n",
       "      <td>7.604868</td>\n",
       "      <td>6.880934</td>\n",
       "      <td>9.027128</td>\n",
       "      <td>4.176175</td>\n",
       "      <td>7.224920</td>\n",
       "      <td>6.085942</td>\n",
       "      <td>6.835999</td>\n",
       "      <td>5.898355</td>\n",
       "      <td>...</td>\n",
       "      <td>9.979005</td>\n",
       "      <td>9.926470</td>\n",
       "      <td>12.719785</td>\n",
       "      <td>12.777792</td>\n",
       "      <td>5.403657</td>\n",
       "      <td>4.870548</td>\n",
       "      <td>4.047380</td>\n",
       "      <td>3.721936</td>\n",
       "      <td>4.516434</td>\n",
       "      <td>4.749940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.067436</td>\n",
       "      <td>7.998090</td>\n",
       "      <td>7.209076</td>\n",
       "      <td>9.723322</td>\n",
       "      <td>4.826126</td>\n",
       "      <td>7.539381</td>\n",
       "      <td>6.250962</td>\n",
       "      <td>8.012549</td>\n",
       "      <td>5.453147</td>\n",
       "      <td>...</td>\n",
       "      <td>11.924749</td>\n",
       "      <td>11.215930</td>\n",
       "      <td>13.605662</td>\n",
       "      <td>13.401342</td>\n",
       "      <td>5.224555</td>\n",
       "      <td>4.895315</td>\n",
       "      <td>3.786437</td>\n",
       "      <td>3.564481</td>\n",
       "      <td>4.430891</td>\n",
       "      <td>4.491416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.068179</td>\n",
       "      <td>8.573674</td>\n",
       "      <td>8.647684</td>\n",
       "      <td>9.613002</td>\n",
       "      <td>4.396581</td>\n",
       "      <td>7.813101</td>\n",
       "      <td>6.007746</td>\n",
       "      <td>7.178156</td>\n",
       "      <td>8.400266</td>\n",
       "      <td>...</td>\n",
       "      <td>12.154405</td>\n",
       "      <td>11.532460</td>\n",
       "      <td>13.764593</td>\n",
       "      <td>13.477800</td>\n",
       "      <td>5.303565</td>\n",
       "      <td>5.052184</td>\n",
       "      <td>4.005343</td>\n",
       "      <td>3.595382</td>\n",
       "      <td>4.563494</td>\n",
       "      <td>4.668827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12.456040</td>\n",
       "      <td>9.098977</td>\n",
       "      <td>6.628784</td>\n",
       "      <td>8.517677</td>\n",
       "      <td>4.154847</td>\n",
       "      <td>8.361843</td>\n",
       "      <td>6.596064</td>\n",
       "      <td>6.347285</td>\n",
       "      <td>4.900380</td>\n",
       "      <td>...</td>\n",
       "      <td>11.969072</td>\n",
       "      <td>11.288801</td>\n",
       "      <td>13.600828</td>\n",
       "      <td>13.379029</td>\n",
       "      <td>4.953429</td>\n",
       "      <td>4.708371</td>\n",
       "      <td>3.892318</td>\n",
       "      <td>3.759429</td>\n",
       "      <td>4.748381</td>\n",
       "      <td>4.521275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12.699958</td>\n",
       "      <td>8.800721</td>\n",
       "      <td>11.556188</td>\n",
       "      <td>9.166309</td>\n",
       "      <td>4.165891</td>\n",
       "      <td>7.923826</td>\n",
       "      <td>6.212754</td>\n",
       "      <td>6.866387</td>\n",
       "      <td>5.405628</td>\n",
       "      <td>...</td>\n",
       "      <td>11.411701</td>\n",
       "      <td>11.169317</td>\n",
       "      <td>13.751442</td>\n",
       "      <td>13.803646</td>\n",
       "      <td>4.892677</td>\n",
       "      <td>4.773806</td>\n",
       "      <td>3.796856</td>\n",
       "      <td>3.577544</td>\n",
       "      <td>4.504385</td>\n",
       "      <td>4.541450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4</td>\n",
       "      <td>12.658228</td>\n",
       "      <td>8.843270</td>\n",
       "      <td>7.672655</td>\n",
       "      <td>9.125912</td>\n",
       "      <td>5.495477</td>\n",
       "      <td>8.603892</td>\n",
       "      <td>7.747514</td>\n",
       "      <td>5.828978</td>\n",
       "      <td>6.926720</td>\n",
       "      <td>...</td>\n",
       "      <td>13.170441</td>\n",
       "      <td>12.676080</td>\n",
       "      <td>14.124837</td>\n",
       "      <td>13.996436</td>\n",
       "      <td>4.913579</td>\n",
       "      <td>4.399176</td>\n",
       "      <td>3.878855</td>\n",
       "      <td>3.680103</td>\n",
       "      <td>4.726784</td>\n",
       "      <td>4.564637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4</td>\n",
       "      <td>12.812823</td>\n",
       "      <td>8.510550</td>\n",
       "      <td>8.729699</td>\n",
       "      <td>9.104402</td>\n",
       "      <td>3.967228</td>\n",
       "      <td>7.719089</td>\n",
       "      <td>7.092496</td>\n",
       "      <td>6.504812</td>\n",
       "      <td>6.157163</td>\n",
       "      <td>...</td>\n",
       "      <td>13.040267</td>\n",
       "      <td>12.403316</td>\n",
       "      <td>13.978009</td>\n",
       "      <td>13.812916</td>\n",
       "      <td>5.189600</td>\n",
       "      <td>4.912618</td>\n",
       "      <td>3.764800</td>\n",
       "      <td>3.664920</td>\n",
       "      <td>4.628355</td>\n",
       "      <td>4.761351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "      <td>12.706991</td>\n",
       "      <td>8.795721</td>\n",
       "      <td>7.772359</td>\n",
       "      <td>8.327273</td>\n",
       "      <td>6.329383</td>\n",
       "      <td>8.550471</td>\n",
       "      <td>6.613332</td>\n",
       "      <td>6.308945</td>\n",
       "      <td>7.494852</td>\n",
       "      <td>...</td>\n",
       "      <td>12.825383</td>\n",
       "      <td>12.439265</td>\n",
       "      <td>14.328373</td>\n",
       "      <td>14.008693</td>\n",
       "      <td>4.931460</td>\n",
       "      <td>4.712895</td>\n",
       "      <td>3.913637</td>\n",
       "      <td>3.700964</td>\n",
       "      <td>4.764693</td>\n",
       "      <td>4.834952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>4</td>\n",
       "      <td>12.684593</td>\n",
       "      <td>8.293938</td>\n",
       "      <td>7.228186</td>\n",
       "      <td>8.494428</td>\n",
       "      <td>6.049414</td>\n",
       "      <td>8.214729</td>\n",
       "      <td>7.287758</td>\n",
       "      <td>5.732710</td>\n",
       "      <td>6.296021</td>\n",
       "      <td>...</td>\n",
       "      <td>13.116581</td>\n",
       "      <td>12.657967</td>\n",
       "      <td>14.390346</td>\n",
       "      <td>14.194904</td>\n",
       "      <td>4.871092</td>\n",
       "      <td>4.739400</td>\n",
       "      <td>3.782980</td>\n",
       "      <td>3.920363</td>\n",
       "      <td>4.665584</td>\n",
       "      <td>4.613326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>4</td>\n",
       "      <td>12.397722</td>\n",
       "      <td>8.843524</td>\n",
       "      <td>8.825100</td>\n",
       "      <td>8.551541</td>\n",
       "      <td>5.002072</td>\n",
       "      <td>8.547894</td>\n",
       "      <td>6.920827</td>\n",
       "      <td>5.738159</td>\n",
       "      <td>6.383309</td>\n",
       "      <td>...</td>\n",
       "      <td>13.117180</td>\n",
       "      <td>12.699932</td>\n",
       "      <td>14.286779</td>\n",
       "      <td>14.088950</td>\n",
       "      <td>4.932377</td>\n",
       "      <td>4.700205</td>\n",
       "      <td>3.952850</td>\n",
       "      <td>3.678112</td>\n",
       "      <td>5.018501</td>\n",
       "      <td>4.704779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 54676 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  1007_s_at   1053_at     117_at    121_at  1255_g_at   1294_at  \\\n",
       "0       1  12.498150  7.604868   6.880934  9.027128   4.176175  7.224920   \n",
       "1       1  13.067436  7.998090   7.209076  9.723322   4.826126  7.539381   \n",
       "2       1  13.068179  8.573674   8.647684  9.613002   4.396581  7.813101   \n",
       "3       1  12.456040  9.098977   6.628784  8.517677   4.154847  8.361843   \n",
       "4       1  12.699958  8.800721  11.556188  9.166309   4.165891  7.923826   \n",
       "..    ...        ...       ...        ...       ...        ...       ...   \n",
       "125     4  12.658228  8.843270   7.672655  9.125912   5.495477  8.603892   \n",
       "126     4  12.812823  8.510550   8.729699  9.104402   3.967228  7.719089   \n",
       "127     4  12.706991  8.795721   7.772359  8.327273   6.329383  8.550471   \n",
       "128     4  12.684593  8.293938   7.228186  8.494428   6.049414  8.214729   \n",
       "129     4  12.397722  8.843524   8.825100  8.551541   5.002072  8.547894   \n",
       "\n",
       "      1316_at   1320_at  1405_i_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0    6.085942  6.835999   5.898355  ...              9.979005   \n",
       "1    6.250962  8.012549   5.453147  ...             11.924749   \n",
       "2    6.007746  7.178156   8.400266  ...             12.154405   \n",
       "3    6.596064  6.347285   4.900380  ...             11.969072   \n",
       "4    6.212754  6.866387   5.405628  ...             11.411701   \n",
       "..        ...       ...        ...  ...                   ...   \n",
       "125  7.747514  5.828978   6.926720  ...             13.170441   \n",
       "126  7.092496  6.504812   6.157163  ...             13.040267   \n",
       "127  6.613332  6.308945   7.494852  ...             12.825383   \n",
       "128  7.287758  5.732710   6.296021  ...             13.116581   \n",
       "129  6.920827  5.738159   6.383309  ...             13.117180   \n",
       "\n",
       "     AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0                9.926470            12.719785            12.777792   \n",
       "1               11.215930            13.605662            13.401342   \n",
       "2               11.532460            13.764593            13.477800   \n",
       "3               11.288801            13.600828            13.379029   \n",
       "4               11.169317            13.751442            13.803646   \n",
       "..                    ...                  ...                  ...   \n",
       "125             12.676080            14.124837            13.996436   \n",
       "126             12.403316            13.978009            13.812916   \n",
       "127             12.439265            14.328373            14.008693   \n",
       "128             12.657967            14.390346            14.194904   \n",
       "129             12.699932            14.286779            14.088950   \n",
       "\n",
       "     AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0          5.403657        4.870548        4.047380         3.721936   \n",
       "1          5.224555        4.895315        3.786437         3.564481   \n",
       "2          5.303565        5.052184        4.005343         3.595382   \n",
       "3          4.953429        4.708371        3.892318         3.759429   \n",
       "4          4.892677        4.773806        3.796856         3.577544   \n",
       "..              ...             ...             ...              ...   \n",
       "125        4.913579        4.399176        3.878855         3.680103   \n",
       "126        5.189600        4.912618        3.764800         3.664920   \n",
       "127        4.931460        4.712895        3.913637         3.700964   \n",
       "128        4.871092        4.739400        3.782980         3.920363   \n",
       "129        4.932377        4.700205        3.952850         3.678112   \n",
       "\n",
       "     AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0           4.516434         4.749940  \n",
       "1           4.430891         4.491416  \n",
       "2           4.563494         4.668827  \n",
       "3           4.748381         4.521275  \n",
       "4           4.504385         4.541450  \n",
       "..               ...              ...  \n",
       "125         4.726784         4.564637  \n",
       "126         4.628355         4.761351  \n",
       "127         4.764693         4.834952  \n",
       "128         4.665584         4.613326  \n",
       "129         5.018501         4.704779  \n",
       "\n",
       "[130 rows x 54676 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and preprocess it\n",
    "# https://www.kaggle.com/datasets/brunogrisci/brain-cancer-gene-expression-cumida\n",
    "\n",
    "brain = pd.read_csv('data/Brain_GSE50161.csv')\n",
    "brain = brain.drop(columns=['samples'])\n",
    "\n",
    "# Identificar cada categoria con un numero\n",
    "brain['type'] = brain['type'].map({\n",
    "    'normal': 0,\n",
    "    'ependymoma': 1,\n",
    "    'glioblastoma': 2,\n",
    "    'medulloblastoma': 3,\n",
    "    'pilocytic_astrocytoma': 4\n",
    "})\n",
    "\n",
    "# Picke store \n",
    "with open('data/brain.pkl', 'wb') as f:\n",
    "    pickle.dump(brain, f)\n",
    "\n",
    "brain = pickle.load(open('data/brain.pkl', 'rb'))\n",
    "brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbrain = brain.drop(['type'], axis=1)\n",
    "ybrain = brain['type']\n",
    "\n",
    "Xbrain_trainval, Xbrain_test, ybrain_trainval, ybrain_test = train_test_split(\n",
    "    Xbrain, \n",
    "    ybrain, test_size=0.15, \n",
    "    random_state=SEED)\n",
    "\n",
    "Xbrain_train, Xbrain_val, ybrain_train, ybrain_val = train_test_split(\n",
    "    Xbrain_trainval, ybrain_trainval, test_size=0.2, \n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type\n",
       " 1    33\n",
       " 2    19\n",
       " 0    12\n",
       " 4    12\n",
       " 3    12\n",
       " Name: count, dtype: int64,\n",
       " type\n",
       " 2    7\n",
       " 1    7\n",
       " 3    5\n",
       " 4    3\n",
       " Name: count, dtype: int64,\n",
       " type\n",
       " 2    8\n",
       " 1    6\n",
       " 3    5\n",
       " 0    1\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybrain_train.value_counts(), ybrain_val.value_counts(), ybrain_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical variables\n",
    "def categorize_variables(df):\n",
    "\n",
    "    categorical = []\n",
    "    numerical = []\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        n_unique = len(unique_values)\n",
    "\n",
    "        if n_unique <= 10:\n",
    "            categorical.append((column, unique_values.tolist()))\n",
    "        else:\n",
    "            numerical.append(column)\n",
    "\n",
    "    return {\n",
    "        'categorical': categorical,\n",
    "        'numerical': numerical\n",
    "    }\n",
    "variables_numericas = categorize_variables(brain.drop('type', axis=1))['numerical']\n",
    "\n",
    "scaler = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), variables_numericas)\n",
    "    ],\n",
    "    remainder='passthrough'  # No escalar las demás variables\n",
    ")\n",
    "\n",
    "# Normalize train set\n",
    "Xbrain_train_scaled = scaler.fit_transform(Xbrain_train)\n",
    "\n",
    "# Normalize val and test set\n",
    "Xbrain_val_scaled = scaler.transform(Xbrain_val)\n",
    "Xbrain_test_scaled = scaler.transform(Xbrain_test)\n",
    "\n",
    "Xbrain_train_scaled = pd.DataFrame(Xbrain_train_scaled, columns=Xbrain_train.columns)\n",
    "Xbrain_val_scaled = pd.DataFrame(Xbrain_val_scaled, columns=Xbrain_val.columns)\n",
    "Xbrain_test_scaled = pd.DataFrame(Xbrain_test_scaled, columns=Xbrain_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noselection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 121ms/step - loss: 95.3444 - sparse_categorical_accuracy: 0.1364 - val_loss: 16.7961 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 23.3642 - sparse_categorical_accuracy: 0.7159 - val_loss: 13.8780 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28.6304 - sparse_categorical_accuracy: 0.7727 - val_loss: 14.8488 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 13.2583 - sparse_categorical_accuracy: 0.8068 - val_loss: 30.7636 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 11.3786 - sparse_categorical_accuracy: 0.8182 - val_loss: 28.0578 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.1803 - sparse_categorical_accuracy: 0.8864 - val_loss: 21.7250 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.2969 - sparse_categorical_accuracy: 0.9318 - val_loss: 19.3814 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9706 - sparse_categorical_accuracy: 0.9205 - val_loss: 18.7385 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.1148 - sparse_categorical_accuracy: 0.9318 - val_loss: 17.3628 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.8441 - sparse_categorical_accuracy: 0.8977 - val_loss: 14.0579 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 1.1595 - sparse_categorical_accuracy: 0.9318 - val_loss: 14.0942 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.5261 - sparse_categorical_accuracy: 0.9545 - val_loss: 18.9250 - val_sparse_categorical_accuracy: 0.8182\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 39.4898 - sparse_categorical_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model = NoSelectionModel(\n",
    "    n_inputs=Xbrain_train_scaled.columns.values.shape[0],\n",
    "    n_class=ybrain_train.unique().shape[0]\n",
    ")       \n",
    "\n",
    "model.fit(\n",
    "    Xbrain_train_scaled,\n",
    "    ybrain_train,\n",
    "    Xbrain_val_scaled,\n",
    "    ybrain_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model.evaluate(Xbrain_test_scaled, ybrain_test)\n",
    "\n",
    "\n",
    "# Pickle store\n",
    "with open('results/brain_NoSelection.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <keras.src.engine.functional.Functional at 0x210661e2cd0>,\n",
       " 'selected_features': array(['1007_s_at', '1053_at', '117_at', ..., 'AFFX-TrpnX-3_at',\n",
       "        'AFFX-TrpnX-5_at', 'AFFX-TrpnX-M_at'], dtype=object),\n",
       " 'predictionsproba': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2776004e-15,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.5754859e-28,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.9797236e-29, 2.6490920e-29, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0284693e-24, 9.7165973e-20, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         1.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4579954e-25,\n",
       "         9.2234659e-10],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00]], dtype=float32),\n",
       " 'results': [39.48979949951172, 0.800000011920929]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose1 = model.get_verbose()\n",
    "verbose1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Number of selected features</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.8</td>\n",
       "      <td>54675</td>\n",
       "      <td>[1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Number of selected features  \\\n",
       "NoSelection       0.8                        54675   \n",
       "\n",
       "                                             Selected Features  \n",
       "NoSelection  [1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results.loc['NoSelection'] = [verbose1['results'][1], verbose1['selected_features'].shape[0], verbose1['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MonoFADL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 142ms/step - loss: 36.2697 - sparse_categorical_accuracy: 0.3068 - val_loss: 6.6767 - val_sparse_categorical_accuracy: 0.7273\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.6120 - sparse_categorical_accuracy: 0.8864 - val_loss: 4.7586 - val_sparse_categorical_accuracy: 0.8182\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.0403 - sparse_categorical_accuracy: 0.9318 - val_loss: 4.6892 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.5855 - sparse_categorical_accuracy: 0.9659 - val_loss: 5.3171 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.2566 - sparse_categorical_accuracy: 0.9886 - val_loss: 5.4063 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.4887 - sparse_categorical_accuracy: 0.9545 - val_loss: 5.3925 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0997 - sparse_categorical_accuracy: 0.9886 - val_loss: 5.2882 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.9512 - sparse_categorical_accuracy: 0.9773 - val_loss: 4.3831 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.8627 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3277 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.0666 - sparse_categorical_accuracy: 0.9773 - val_loss: 3.1079 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.8813 - sparse_categorical_accuracy: 0.9886 - val_loss: 3.2191 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.8183 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9296 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.8044 - sparse_categorical_accuracy: 1.0000 - val_loss: 4.5184 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7919 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.4146 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7781 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.6737 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7622 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.9996 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7473 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.1444 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.7323 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.3253 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7148 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.6424 - val_sparse_categorical_accuracy: 0.8636\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.6989 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.9953 - val_sparse_categorical_accuracy: 0.8636\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 34.2686 - sparse_categorical_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "model2 = MonoFADLModel(\n",
    "    n_inputs=Xbrain_train_scaled.columns.values.shape[0],\n",
    "    n_class=ybrain_train.unique().shape[0]\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    Xbrain_train_scaled,\n",
    "    ybrain_train,\n",
    "    Xbrain_val_scaled,\n",
    "    ybrain_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model2.evaluate(Xbrain_test_scaled, ybrain_test)\n",
    "\n",
    "model2.get_verbose()\n",
    "\n",
    "# Pickle store\n",
    "with open('results/brain_MonoFADL.pkl', 'wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <keras.src.engine.functional.Functional at 0x2100dba9890>,\n",
       " 'selected_features': array(['1007_s_at', '1053_at', '117_at', ..., 'AFFX-r2-Ec-bioD-3_at',\n",
       "        'AFFX-r2-P1-cre-3_at', 'AFFX-ThrX-M_at'], dtype=object),\n",
       " 'predictionsproba': array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.8119153e-35,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.4210849e-16,\n",
       "         2.2182031e-34],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.1431732e-32,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.3035374e-15,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [2.2073346e-31, 0.0000000e+00, 9.7676426e-01, 0.0000000e+00,\n",
       "         2.3235690e-02],\n",
       "        [3.5125761e-26, 4.5882503e-37, 1.0000000e+00, 3.8640193e-14,\n",
       "         7.8376684e-14],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 9.9999964e-01, 3.6499864e-07,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.7956791e-26,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "         0.0000000e+00]], dtype=float32),\n",
       " 'results': [34.26856994628906, 0.8999999761581421]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose2 = model2.get_verbose()\n",
    "verbose2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Number of selected features</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.8</td>\n",
       "      <td>54675</td>\n",
       "      <td>[1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>0.9</td>\n",
       "      <td>17481</td>\n",
       "      <td>[1007_s_at, 1053_at, 117_at, 1294_at, 1438_at,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy  Number of selected features  \\\n",
       "NoSelection       0.8                        54675   \n",
       "MonoFADL          0.9                        17481   \n",
       "\n",
       "                                             Selected Features  \n",
       "NoSelection  [1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...  \n",
       "MonoFADL     [1007_s_at, 1053_at, 117_at, 1294_at, 1438_at,...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results.loc['MonoFADL'] = [verbose2['results'][1], verbose2['selected_features'].shape[0], verbose2['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MultiFADL One-versus-Rest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training model class 0 vs rest\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 132ms/step - loss: 44.7842 - binary_accuracy: 0.6591 - val_loss: 3.2477 - val_binary_accuracy: 0.9545\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.6759 - binary_accuracy: 1.0000 - val_loss: 2.0043 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 2.6772 - binary_accuracy: 0.9318 - val_loss: 3.3464 - val_binary_accuracy: 0.7273\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 2.1730 - binary_accuracy: 0.9318 - val_loss: 2.1405 - val_binary_accuracy: 0.9091\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.8626 - binary_accuracy: 0.9886 - val_loss: 1.7413 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.6588 - binary_accuracy: 0.9773 - val_loss: 1.4397 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.2950 - binary_accuracy: 1.0000 - val_loss: 1.1442 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9846 - binary_accuracy: 1.0000 - val_loss: 0.8689 - val_binary_accuracy: 0.9545\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7069 - binary_accuracy: 1.0000 - val_loss: 0.6524 - val_binary_accuracy: 0.9545\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.4893 - binary_accuracy: 1.0000 - val_loss: 0.5246 - val_binary_accuracy: 0.9545\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3509 - binary_accuracy: 1.0000 - val_loss: 0.3895 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.2465 - binary_accuracy: 1.0000 - val_loss: 0.2970 - val_binary_accuracy: 0.9545\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1741 - binary_accuracy: 1.0000 - val_loss: 0.2565 - val_binary_accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1433 - binary_accuracy: 1.0000 - val_loss: 0.2103 - val_binary_accuracy: 0.9545\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1145 - binary_accuracy: 1.0000 - val_loss: 0.1777 - val_binary_accuracy: 0.9545\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0975 - binary_accuracy: 1.0000 - val_loss: 0.1331 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0821 - binary_accuracy: 1.0000 - val_loss: 0.1088 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0721 - binary_accuracy: 1.0000 - val_loss: 0.0967 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0664 - binary_accuracy: 1.0000 - val_loss: 0.0866 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0578 - binary_accuracy: 1.0000 - val_loss: 0.0769 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0495 - binary_accuracy: 1.0000 - val_loss: 0.0763 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0451 - binary_accuracy: 1.0000 - val_loss: 0.0680 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0411 - binary_accuracy: 1.0000 - val_loss: 0.0603 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0372 - binary_accuracy: 1.0000 - val_loss: 0.0571 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0346 - binary_accuracy: 1.0000 - val_loss: 0.0601 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0325 - binary_accuracy: 1.0000 - val_loss: 0.0685 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0301 - binary_accuracy: 1.0000 - val_loss: 0.0698 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0280 - binary_accuracy: 1.0000 - val_loss: 0.0625 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0270 - binary_accuracy: 1.0000 - val_loss: 0.0693 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0255 - binary_accuracy: 1.0000 - val_loss: 0.0723 - val_binary_accuracy: 0.9545\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0244 - binary_accuracy: 1.0000 - val_loss: 0.0671 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 0.0727 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0226 - binary_accuracy: 1.0000 - val_loss: 0.0754 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0242 - binary_accuracy: 1.0000 - val_loss: 0.0385 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0226 - binary_accuracy: 1.0000 - val_loss: 0.0319 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0220 - binary_accuracy: 1.0000 - val_loss: 0.0308 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0212 - binary_accuracy: 1.0000 - val_loss: 0.0315 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0211 - binary_accuracy: 1.0000 - val_loss: 0.0375 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0198 - binary_accuracy: 1.0000 - val_loss: 0.0345 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0192 - binary_accuracy: 1.0000 - val_loss: 0.0351 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0184 - binary_accuracy: 1.0000 - val_loss: 0.0383 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0186 - binary_accuracy: 1.0000 - val_loss: 0.0291 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0166 - binary_accuracy: 1.0000 - val_loss: 0.0284 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.0164 - binary_accuracy: 1.0000 - val_loss: 0.0278 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0158 - binary_accuracy: 1.0000 - val_loss: 0.0313 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0149 - binary_accuracy: 1.0000 - val_loss: 0.0322 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0163 - binary_accuracy: 1.0000 - val_loss: 0.0307 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0142 - binary_accuracy: 1.0000 - val_loss: 0.0332 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0140 - binary_accuracy: 1.0000 - val_loss: 0.0293 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0149 - binary_accuracy: 1.0000 - val_loss: 0.0274 - val_binary_accuracy: 1.0000\n",
      "--> Training model class 1 vs rest\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 123ms/step - loss: 65.9134 - binary_accuracy: 0.6591 - val_loss: 7.2414 - val_binary_accuracy: 0.9545\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 5.0285 - binary_accuracy: 0.9886 - val_loss: 2.8796 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 2.3611 - binary_accuracy: 1.0000 - val_loss: 1.4500 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 1.1836 - binary_accuracy: 1.0000 - val_loss: 0.6697 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5255 - binary_accuracy: 1.0000 - val_loss: 0.2886 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2113 - binary_accuracy: 1.0000 - val_loss: 0.1879 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1261 - binary_accuracy: 1.0000 - val_loss: 0.1665 - val_binary_accuracy: 0.9091\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.1187 - binary_accuracy: 1.0000 - val_loss: 0.1421 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0859 - binary_accuracy: 1.0000 - val_loss: 0.1286 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0950 - binary_accuracy: 1.0000 - val_loss: 0.1267 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0923 - binary_accuracy: 1.0000 - val_loss: 0.1231 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0836 - binary_accuracy: 1.0000 - val_loss: 0.1208 - val_binary_accuracy: 0.9545\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0704 - binary_accuracy: 1.0000 - val_loss: 0.1118 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0675 - binary_accuracy: 1.0000 - val_loss: 0.1092 - val_binary_accuracy: 0.9545\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0656 - binary_accuracy: 1.0000 - val_loss: 0.1048 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0598 - binary_accuracy: 1.0000 - val_loss: 0.1074 - val_binary_accuracy: 0.9545\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0581 - binary_accuracy: 1.0000 - val_loss: 0.1020 - val_binary_accuracy: 0.9545\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0556 - binary_accuracy: 1.0000 - val_loss: 0.0987 - val_binary_accuracy: 0.9545\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0532 - binary_accuracy: 1.0000 - val_loss: 0.0944 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0511 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0494 - binary_accuracy: 1.0000 - val_loss: 0.0892 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0476 - binary_accuracy: 1.0000 - val_loss: 0.0789 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0461 - binary_accuracy: 1.0000 - val_loss: 0.0799 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0443 - binary_accuracy: 1.0000 - val_loss: 0.0738 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0428 - binary_accuracy: 1.0000 - val_loss: 0.0725 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0416 - binary_accuracy: 1.0000 - val_loss: 0.0675 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0407 - binary_accuracy: 1.0000 - val_loss: 0.0651 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0388 - binary_accuracy: 1.0000 - val_loss: 0.0602 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0378 - binary_accuracy: 1.0000 - val_loss: 0.0586 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0366 - binary_accuracy: 1.0000 - val_loss: 0.0575 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0358 - binary_accuracy: 1.0000 - val_loss: 0.0539 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0347 - binary_accuracy: 1.0000 - val_loss: 0.0534 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0339 - binary_accuracy: 1.0000 - val_loss: 0.0528 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0328 - binary_accuracy: 1.0000 - val_loss: 0.0517 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0321 - binary_accuracy: 1.0000 - val_loss: 0.0496 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0312 - binary_accuracy: 1.0000 - val_loss: 0.0479 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0306 - binary_accuracy: 1.0000 - val_loss: 0.0479 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0298 - binary_accuracy: 1.0000 - val_loss: 0.0468 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0292 - binary_accuracy: 1.0000 - val_loss: 0.0467 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0286 - binary_accuracy: 1.0000 - val_loss: 0.0459 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0280 - binary_accuracy: 1.0000 - val_loss: 0.0460 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0274 - binary_accuracy: 1.0000 - val_loss: 0.0452 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0272 - binary_accuracy: 1.0000 - val_loss: 0.0448 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0264 - binary_accuracy: 1.0000 - val_loss: 0.0470 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0260 - binary_accuracy: 1.0000 - val_loss: 0.0463 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0258 - binary_accuracy: 1.0000 - val_loss: 0.0425 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0255 - binary_accuracy: 1.0000 - val_loss: 0.0451 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0248 - binary_accuracy: 1.0000 - val_loss: 0.0332 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0243 - binary_accuracy: 1.0000 - val_loss: 0.0361 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0238 - binary_accuracy: 1.0000 - val_loss: 0.0355 - val_binary_accuracy: 1.0000\n",
      "--> Training model class 2 vs rest\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 56.0723 - binary_accuracy: 0.6136 - val_loss: 6.6823 - val_binary_accuracy: 0.7273\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.3092 - binary_accuracy: 0.8409 - val_loss: 4.8809 - val_binary_accuracy: 0.8636\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6156 - binary_accuracy: 0.9205 - val_loss: 4.0680 - val_binary_accuracy: 0.7727\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.4425 - binary_accuracy: 0.9432 - val_loss: 2.9811 - val_binary_accuracy: 0.8182\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.4853 - binary_accuracy: 0.9773 - val_loss: 2.1708 - val_binary_accuracy: 0.8182\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.7850 - binary_accuracy: 0.9773 - val_loss: 1.5290 - val_binary_accuracy: 0.8636\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 1.2075 - binary_accuracy: 0.9886 - val_loss: 1.0268 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.8128 - binary_accuracy: 1.0000 - val_loss: 0.7180 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5234 - binary_accuracy: 1.0000 - val_loss: 0.5102 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3404 - binary_accuracy: 1.0000 - val_loss: 0.4219 - val_binary_accuracy: 0.9545\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2439 - binary_accuracy: 1.0000 - val_loss: 0.3722 - val_binary_accuracy: 0.9545\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1895 - binary_accuracy: 1.0000 - val_loss: 0.3551 - val_binary_accuracy: 0.9545\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1684 - binary_accuracy: 1.0000 - val_loss: 0.3116 - val_binary_accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1448 - binary_accuracy: 1.0000 - val_loss: 0.2947 - val_binary_accuracy: 0.9545\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1237 - binary_accuracy: 1.0000 - val_loss: 0.2797 - val_binary_accuracy: 0.9545\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1114 - binary_accuracy: 1.0000 - val_loss: 0.2835 - val_binary_accuracy: 0.9545\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1030 - binary_accuracy: 1.0000 - val_loss: 0.2853 - val_binary_accuracy: 0.9091\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0923 - binary_accuracy: 1.0000 - val_loss: 0.2985 - val_binary_accuracy: 0.9091\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0853 - binary_accuracy: 1.0000 - val_loss: 0.2795 - val_binary_accuracy: 0.9091\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0776 - binary_accuracy: 1.0000 - val_loss: 0.2842 - val_binary_accuracy: 0.9091\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0720 - binary_accuracy: 1.0000 - val_loss: 0.2984 - val_binary_accuracy: 0.9091\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0671 - binary_accuracy: 1.0000 - val_loss: 0.2771 - val_binary_accuracy: 0.9091\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0629 - binary_accuracy: 1.0000 - val_loss: 0.2907 - val_binary_accuracy: 0.9091\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0599 - binary_accuracy: 1.0000 - val_loss: 0.2844 - val_binary_accuracy: 0.9091\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0571 - binary_accuracy: 1.0000 - val_loss: 0.2946 - val_binary_accuracy: 0.9091\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0534 - binary_accuracy: 1.0000 - val_loss: 0.2978 - val_binary_accuracy: 0.9091\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0513 - binary_accuracy: 1.0000 - val_loss: 0.2712 - val_binary_accuracy: 0.9091\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0506 - binary_accuracy: 1.0000 - val_loss: 0.3455 - val_binary_accuracy: 0.8636\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0460 - binary_accuracy: 1.0000 - val_loss: 0.3728 - val_binary_accuracy: 0.9091\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0449 - binary_accuracy: 1.0000 - val_loss: 0.3859 - val_binary_accuracy: 0.8636\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0425 - binary_accuracy: 1.0000 - val_loss: 0.3454 - val_binary_accuracy: 0.8636\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0409 - binary_accuracy: 1.0000 - val_loss: 0.2976 - val_binary_accuracy: 0.9091\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0393 - binary_accuracy: 1.0000 - val_loss: 0.2756 - val_binary_accuracy: 0.9091\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0380 - binary_accuracy: 1.0000 - val_loss: 0.2872 - val_binary_accuracy: 0.9091\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0367 - binary_accuracy: 1.0000 - val_loss: 0.2137 - val_binary_accuracy: 0.9091\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0360 - binary_accuracy: 1.0000 - val_loss: 0.2160 - val_binary_accuracy: 0.9091\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0344 - binary_accuracy: 1.0000 - val_loss: 0.1647 - val_binary_accuracy: 0.9545\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0345 - binary_accuracy: 1.0000 - val_loss: 0.1544 - val_binary_accuracy: 0.9545\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0337 - binary_accuracy: 1.0000 - val_loss: 0.3129 - val_binary_accuracy: 0.8636\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0323 - binary_accuracy: 1.0000 - val_loss: 0.1788 - val_binary_accuracy: 0.9545\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0308 - binary_accuracy: 1.0000 - val_loss: 0.1768 - val_binary_accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0303 - binary_accuracy: 1.0000 - val_loss: 0.2439 - val_binary_accuracy: 0.9545\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0300 - binary_accuracy: 1.0000 - val_loss: 0.1760 - val_binary_accuracy: 0.9545\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0284 - binary_accuracy: 1.0000 - val_loss: 0.2387 - val_binary_accuracy: 0.9545\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0278 - binary_accuracy: 1.0000 - val_loss: 0.2323 - val_binary_accuracy: 0.9091\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0273 - binary_accuracy: 1.0000 - val_loss: 0.1182 - val_binary_accuracy: 0.9545\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0267 - binary_accuracy: 1.0000 - val_loss: 0.1361 - val_binary_accuracy: 0.9545\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0260 - binary_accuracy: 1.0000 - val_loss: 0.2186 - val_binary_accuracy: 0.9545\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0253 - binary_accuracy: 1.0000 - val_loss: 0.1974 - val_binary_accuracy: 0.9545\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0246 - binary_accuracy: 1.0000 - val_loss: 0.1266 - val_binary_accuracy: 0.9545\n",
      "--> Training model class 4 vs rest\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 124ms/step - loss: 72.9308 - binary_accuracy: 0.3523 - val_loss: 13.7970 - val_binary_accuracy: 0.8182\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.8015 - binary_accuracy: 0.9432 - val_loss: 4.2703 - val_binary_accuracy: 0.8636\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.6286 - binary_accuracy: 0.9659 - val_loss: 1.9010 - val_binary_accuracy: 0.8636\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.1488 - binary_accuracy: 0.9886 - val_loss: 1.0413 - val_binary_accuracy: 0.8636\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5216 - binary_accuracy: 0.9773 - val_loss: 0.5547 - val_binary_accuracy: 0.8636\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.2673 - binary_accuracy: 1.0000 - val_loss: 0.3720 - val_binary_accuracy: 0.8636\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1945 - binary_accuracy: 1.0000 - val_loss: 0.2624 - val_binary_accuracy: 0.9545\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1566 - binary_accuracy: 1.0000 - val_loss: 0.2389 - val_binary_accuracy: 0.9545\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1321 - binary_accuracy: 1.0000 - val_loss: 0.2282 - val_binary_accuracy: 0.9545\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1182 - binary_accuracy: 1.0000 - val_loss: 0.2442 - val_binary_accuracy: 0.9545\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1042 - binary_accuracy: 1.0000 - val_loss: 0.2506 - val_binary_accuracy: 0.9091\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0931 - binary_accuracy: 1.0000 - val_loss: 0.2372 - val_binary_accuracy: 0.9545\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0858 - binary_accuracy: 1.0000 - val_loss: 0.2127 - val_binary_accuracy: 0.9545\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0794 - binary_accuracy: 1.0000 - val_loss: 0.2148 - val_binary_accuracy: 0.9545\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0751 - binary_accuracy: 1.0000 - val_loss: 0.2197 - val_binary_accuracy: 0.9545\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0710 - binary_accuracy: 1.0000 - val_loss: 0.2141 - val_binary_accuracy: 0.9545\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0677 - binary_accuracy: 1.0000 - val_loss: 0.2149 - val_binary_accuracy: 0.9545\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0640 - binary_accuracy: 1.0000 - val_loss: 0.2009 - val_binary_accuracy: 0.9545\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0607 - binary_accuracy: 1.0000 - val_loss: 0.1680 - val_binary_accuracy: 0.9545\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0584 - binary_accuracy: 1.0000 - val_loss: 0.1695 - val_binary_accuracy: 0.9545\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0557 - binary_accuracy: 1.0000 - val_loss: 0.1726 - val_binary_accuracy: 0.9545\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0539 - binary_accuracy: 1.0000 - val_loss: 0.2096 - val_binary_accuracy: 0.9545\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0520 - binary_accuracy: 1.0000 - val_loss: 0.1844 - val_binary_accuracy: 0.9545\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0501 - binary_accuracy: 1.0000 - val_loss: 0.1859 - val_binary_accuracy: 0.9545\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0485 - binary_accuracy: 1.0000 - val_loss: 0.1773 - val_binary_accuracy: 0.9545\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0466 - binary_accuracy: 1.0000 - val_loss: 0.1816 - val_binary_accuracy: 0.9545\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0452 - binary_accuracy: 1.0000 - val_loss: 0.1755 - val_binary_accuracy: 0.9545\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0440 - binary_accuracy: 1.0000 - val_loss: 0.1684 - val_binary_accuracy: 0.9545\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0430 - binary_accuracy: 1.0000 - val_loss: 0.1791 - val_binary_accuracy: 0.9545\n",
      "--> Training model class 3 vs rest\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 118ms/step - loss: 98.4157 - binary_accuracy: 0.2841 - val_loss: 17.0012 - val_binary_accuracy: 0.6818\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.1464 - binary_accuracy: 0.8523 - val_loss: 3.4934 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.6992 - binary_accuracy: 0.9545 - val_loss: 2.9010 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 2.6602 - binary_accuracy: 1.0000 - val_loss: 2.1414 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 1.9474 - binary_accuracy: 1.0000 - val_loss: 1.5054 - val_binary_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 1.3470 - binary_accuracy: 1.0000 - val_loss: 1.0167 - val_binary_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.9137 - binary_accuracy: 1.0000 - val_loss: 0.7071 - val_binary_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.6507 - binary_accuracy: 0.9886 - val_loss: 0.5002 - val_binary_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4666 - binary_accuracy: 0.9886 - val_loss: 0.3566 - val_binary_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.3275 - binary_accuracy: 1.0000 - val_loss: 0.2773 - val_binary_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.2494 - binary_accuracy: 1.0000 - val_loss: 0.2134 - val_binary_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1987 - binary_accuracy: 1.0000 - val_loss: 0.1764 - val_binary_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1570 - binary_accuracy: 1.0000 - val_loss: 0.1486 - val_binary_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.1223 - binary_accuracy: 1.0000 - val_loss: 0.1248 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0973 - binary_accuracy: 1.0000 - val_loss: 0.1132 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0827 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0677 - binary_accuracy: 1.0000 - val_loss: 0.0853 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0563 - binary_accuracy: 1.0000 - val_loss: 0.0822 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0492 - binary_accuracy: 1.0000 - val_loss: 0.0773 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0428 - binary_accuracy: 1.0000 - val_loss: 0.0797 - val_binary_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0381 - binary_accuracy: 1.0000 - val_loss: 0.0754 - val_binary_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0357 - binary_accuracy: 1.0000 - val_loss: 0.0774 - val_binary_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0342 - binary_accuracy: 1.0000 - val_loss: 0.0648 - val_binary_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0318 - binary_accuracy: 1.0000 - val_loss: 0.0595 - val_binary_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0302 - binary_accuracy: 1.0000 - val_loss: 0.0551 - val_binary_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0290 - binary_accuracy: 1.0000 - val_loss: 0.0433 - val_binary_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0272 - binary_accuracy: 1.0000 - val_loss: 0.0423 - val_binary_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0260 - binary_accuracy: 1.0000 - val_loss: 0.0482 - val_binary_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0254 - binary_accuracy: 1.0000 - val_loss: 0.0355 - val_binary_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0247 - binary_accuracy: 1.0000 - val_loss: 0.0341 - val_binary_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0239 - binary_accuracy: 1.0000 - val_loss: 0.0310 - val_binary_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0243 - binary_accuracy: 1.0000 - val_loss: 0.0352 - val_binary_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0232 - binary_accuracy: 1.0000 - val_loss: 0.0427 - val_binary_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0221 - binary_accuracy: 1.0000 - val_loss: 0.0552 - val_binary_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0215 - binary_accuracy: 1.0000 - val_loss: 0.0637 - val_binary_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0226 - binary_accuracy: 1.0000 - val_loss: 0.0535 - val_binary_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0203 - binary_accuracy: 1.0000 - val_loss: 0.0274 - val_binary_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0200 - binary_accuracy: 1.0000 - val_loss: 0.0306 - val_binary_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0197 - binary_accuracy: 1.0000 - val_loss: 0.0321 - val_binary_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0211 - binary_accuracy: 1.0000 - val_loss: 0.0260 - val_binary_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0190 - binary_accuracy: 1.0000 - val_loss: 0.0245 - val_binary_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0195 - binary_accuracy: 1.0000 - val_loss: 0.0259 - val_binary_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0181 - binary_accuracy: 1.0000 - val_loss: 0.0450 - val_binary_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0186 - binary_accuracy: 1.0000 - val_loss: 0.0264 - val_binary_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0175 - binary_accuracy: 1.0000 - val_loss: 0.0257 - val_binary_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0172 - binary_accuracy: 1.0000 - val_loss: 0.0251 - val_binary_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0169 - binary_accuracy: 1.0000 - val_loss: 0.0380 - val_binary_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0157 - binary_accuracy: 1.0000 - val_loss: 0.0253 - val_binary_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0155 - binary_accuracy: 1.0000 - val_loss: 0.0275 - val_binary_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0157 - binary_accuracy: 1.0000 - val_loss: 0.0345 - val_binary_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021071836340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021071837380> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1694 - binary_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5618 - binary_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6266 - binary_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2644 - binary_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0218 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model3 = MultiFADLModelOvR(\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    Xbrain_train_scaled,\n",
    "    ybrain_train,\n",
    "    Xbrain_val_scaled,\n",
    "    ybrain_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model3.evaluate(Xbrain_test_scaled, ybrain_test)\n",
    "\n",
    "model3.get_verbose()\n",
    "\n",
    "# Pickle store\n",
    "with open('results/brain_MultiFADL.pkl', 'wb') as f:\n",
    "    pickle.dump(model3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {0: <src.MonoFADLModel.MonoFADLModel at 0x21064eff850>,\n",
       "  1: <src.MonoFADLModel.MonoFADLModel at 0x210661d6f50>,\n",
       "  2: <src.MonoFADLModel.MonoFADLModel at 0x2100d683190>,\n",
       "  4: <src.MonoFADLModel.MonoFADLModel at 0x21075a75fd0>,\n",
       "  3: <src.MonoFADLModel.MonoFADLModel at 0x210759d9510>},\n",
       " 'selected_features_per_class': {0: array(['204366_s_at', '207227_x_at', '208675_s_at', '218651_s_at',\n",
       "         '219283_at', '219317_at', '234979_at', '239764_at', '244471_x_at',\n",
       "         '38398_at'], dtype=object),\n",
       "  1: array(['1553734_at', '204874_x_at', '204932_at', '204933_s_at',\n",
       "         '205464_at', '205578_at', '206773_at', '210033_s_at', '214147_at',\n",
       "         '220156_at', '220334_at', '231192_at', '232984_at', '233516_s_at',\n",
       "         '236085_at', '239942_at', '242162_at', '244364_at', '41660_at'],\n",
       "        dtype=object),\n",
       "  2: array(['1557359_at', '1558568_a_at', '1569241_a_at', '202995_s_at',\n",
       "         '204639_at', '205775_at', '217784_at', '222118_at', '224376_s_at',\n",
       "         '228235_at', '228850_s_at', '229228_at', '235013_at', '235438_at',\n",
       "         '235830_at', '236937_at', '237737_at', '240179_at', '242037_at'],\n",
       "        dtype=object),\n",
       "  4: array(['1553943_at', '1554262_s_at', '1557944_s_at', '1558105_a_at',\n",
       "         '1566715_at', '1569879_a_at', '201790_s_at', '201978_s_at',\n",
       "         '204022_at', '205156_s_at', '205398_s_at', '205926_at',\n",
       "         '206869_at', '206941_x_at', '207864_at', '211586_s_at',\n",
       "         '211880_x_at', '219044_at', '221226_s_at', '221661_at',\n",
       "         '224018_s_at', '224727_at', '226237_at', '228593_at', '228968_at',\n",
       "         '229779_at', '232246_at', '232313_at', '232764_at', '234237_s_at',\n",
       "         '234458_at', '234751_s_at', '235270_at', '235397_at', '235400_at',\n",
       "         '236018_at', '236247_at', '238770_at', '240518_at', '242978_x_at',\n",
       "         '243779_at', '244561_at'], dtype=object),\n",
       "  3: array(['1562309_s_at', '204130_at', '209170_s_at', '212636_at',\n",
       "         '214030_at', '227230_s_at', '227242_s_at', '230248_x_at',\n",
       "         '232781_at', '234394_at', '237007_at', '239911_at'], dtype=object)},\n",
       " 'predictionsproba_per_model': {0: array([[5.0535090e-03],\n",
       "         [6.3349304e-05],\n",
       "         [4.9305097e-05],\n",
       "         [1.7834930e-03],\n",
       "         [4.4157267e-05],\n",
       "         [3.5599698e-04],\n",
       "         [9.9259347e-01],\n",
       "         [9.2928416e-01],\n",
       "         [8.1047002e-04],\n",
       "         [5.0852133e-05],\n",
       "         [1.8447657e-06],\n",
       "         [1.4790862e-06],\n",
       "         [3.7058129e-05],\n",
       "         [7.7707024e-05],\n",
       "         [2.3393637e-01],\n",
       "         [1.4630129e-05],\n",
       "         [1.0783898e-03],\n",
       "         [2.6151180e-02],\n",
       "         [2.0534015e-01],\n",
       "         [1.5944053e-05]], dtype=float32),\n",
       "  1: array([[1.0909980e-04],\n",
       "         [1.6559858e-05],\n",
       "         [3.9487903e-05],\n",
       "         [9.9280703e-01],\n",
       "         [4.8580719e-04],\n",
       "         [9.8213989e-01],\n",
       "         [1.6181775e-04],\n",
       "         [5.5132009e-04],\n",
       "         [1.8791822e-03],\n",
       "         [9.7605705e-01],\n",
       "         [2.0610936e-05],\n",
       "         [9.5851283e-05],\n",
       "         [1.7936933e-05],\n",
       "         [9.9102819e-01],\n",
       "         [1.2318189e-05],\n",
       "         [9.9588495e-01],\n",
       "         [2.6023312e-05],\n",
       "         [2.9142480e-04],\n",
       "         [2.4197318e-04],\n",
       "         [7.3881051e-06]], dtype=float32),\n",
       "  2: array([[6.9622098e-07],\n",
       "         [9.9431580e-01],\n",
       "         [9.8219001e-01],\n",
       "         [4.2819687e-05],\n",
       "         [9.6512538e-01],\n",
       "         [1.2115527e-05],\n",
       "         [8.2185160e-08],\n",
       "         [6.8314708e-05],\n",
       "         [9.6055514e-01],\n",
       "         [4.0248121e-04],\n",
       "         [4.8633355e-01],\n",
       "         [8.2133341e-01],\n",
       "         [2.6737077e-06],\n",
       "         [5.5243794e-02],\n",
       "         [1.5242033e-05],\n",
       "         [2.6723354e-10],\n",
       "         [9.2896074e-01],\n",
       "         [6.4199793e-01],\n",
       "         [6.4067125e-01],\n",
       "         [9.5531001e-04]], dtype=float32),\n",
       "  4: array([[0.00488746],\n",
       "         [0.16051501],\n",
       "         [0.00508672],\n",
       "         [0.01394361],\n",
       "         [0.00898923],\n",
       "         [0.00146593],\n",
       "         [0.01163424],\n",
       "         [0.00559209],\n",
       "         [0.01206078],\n",
       "         [0.03249338],\n",
       "         [0.9688604 ],\n",
       "         [0.11790181],\n",
       "         [0.00425289],\n",
       "         [0.02509753],\n",
       "         [0.01986169],\n",
       "         [0.00455161],\n",
       "         [0.13885346],\n",
       "         [0.28939623],\n",
       "         [0.0326786 ],\n",
       "         [0.00170954]], dtype=float32),\n",
       "  3: array([[9.9086910e-01],\n",
       "         [4.1462835e-03],\n",
       "         [8.1059360e-04],\n",
       "         [6.9956673e-06],\n",
       "         [2.5049347e-04],\n",
       "         [1.9476133e-04],\n",
       "         [3.8077377e-03],\n",
       "         [1.7614807e-03],\n",
       "         [4.6882522e-04],\n",
       "         [1.2050725e-03],\n",
       "         [3.1292292e-03],\n",
       "         [1.4619870e-04],\n",
       "         [9.7482866e-01],\n",
       "         [8.8744609e-06],\n",
       "         [9.7367543e-01],\n",
       "         [7.9707016e-04],\n",
       "         [2.4638785e-04],\n",
       "         [1.7195571e-03],\n",
       "         [8.9382166e-01],\n",
       "         [9.9697578e-01]], dtype=float32)},\n",
       " 'predictions_global': array([3, 2, 2, 1, 2, 1, 0, 0, 2, 1, 4, 2, 3, 1, 3, 1, 2, 2, 3, 3],\n",
       "       dtype=int64),\n",
       " 'lossAcc_per_model': {0: [0.1694401651620865, 0.949999988079071],\n",
       "  1: [0.5618118643760681, 0.949999988079071],\n",
       "  2: [0.6266220808029175, 0.8999999761581421],\n",
       "  4: [0.26435402035713196, 0.949999988079071],\n",
       "  3: [0.021767325699329376, 1.0]},\n",
       " 'acc_global': 0.9}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose3 = model3.get_verbose()\n",
    "verbose3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Number of selected features</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.8</td>\n",
       "      <td>54675</td>\n",
       "      <td>[1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>0.9</td>\n",
       "      <td>17481</td>\n",
       "      <td>[1007_s_at, 1053_at, 117_at, 1294_at, 1438_at,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiFADL</th>\n",
       "      <td>0.9</td>\n",
       "      <td>{0: 10, 1: 19, 2: 19, 4: 42, 3: 12}</td>\n",
       "      <td>{0: ['204366_s_at', '207227_x_at', '208675_s_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy          Number of selected features  \\\n",
       "NoSelection       0.8                                54675   \n",
       "MonoFADL          0.9                                17481   \n",
       "MultiFADL         0.9  {0: 10, 1: 19, 2: 19, 4: 42, 3: 12}   \n",
       "\n",
       "                                             Selected Features  \n",
       "NoSelection  [1007_s_at, 1053_at, 117_at, 121_at, 1255_g_at...  \n",
       "MonoFADL     [1007_s_at, 1053_at, 117_at, 1294_at, 1438_at,...  \n",
       "MultiFADL    {0: ['204366_s_at', '207227_x_at', '208675_s_a...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results.loc['MultiFADL'] = [verbose3['acc_global'], \n",
    "                                        {clas: verbose3['selected_features_per_class'][clas].shape[0] for clas in verbose3['selected_features_per_class']},\n",
    "                                        verbose3['selected_features_per_class']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results.to_csv('results/brain_ComparativeResults.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fadl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
