{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas MultiFADL One-versus-Rest. hepatitis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src import utils\n",
    "\n",
    "from src.MonoFADLModel import MonoFADLModel\n",
    "from src.MultiFADLModelOvR import MultiFADLModelOvR\n",
    "from src.NoSelectionModel import NoSelectionModel\n",
    "\n",
    "# Seed for neural network executions\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results = pd.DataFrame(columns=['test_loss', 'test_accuracy', 'test_f1', 'number of selected features', 'selected Features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Nausea/Vomting</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Fatigue &amp; generalized bone ache</th>\n",
       "      <th>Jaundice</th>\n",
       "      <th>Epigastric pain</th>\n",
       "      <th>...</th>\n",
       "      <th>ALT 36</th>\n",
       "      <th>ALT 48</th>\n",
       "      <th>ALT after 24 w</th>\n",
       "      <th>RNA Base</th>\n",
       "      <th>RNA 4</th>\n",
       "      <th>RNA 12</th>\n",
       "      <th>RNA EOT</th>\n",
       "      <th>RNA EF</th>\n",
       "      <th>Baseline histological Grading</th>\n",
       "      <th>Baselinehistological staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>655330</td>\n",
       "      <td>634536</td>\n",
       "      <td>288194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>123</td>\n",
       "      <td>44</td>\n",
       "      <td>40620</td>\n",
       "      <td>538635</td>\n",
       "      <td>637056</td>\n",
       "      <td>336804</td>\n",
       "      <td>31085</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>571148</td>\n",
       "      <td>661346</td>\n",
       "      <td>5</td>\n",
       "      <td>735945</td>\n",
       "      <td>558829</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>77</td>\n",
       "      <td>33</td>\n",
       "      <td>1041941</td>\n",
       "      <td>449939</td>\n",
       "      <td>585688</td>\n",
       "      <td>744463</td>\n",
       "      <td>582301</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>660410</td>\n",
       "      <td>738756</td>\n",
       "      <td>3731527</td>\n",
       "      <td>338946</td>\n",
       "      <td>242861</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>387795</td>\n",
       "      <td>55938</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>481378</td>\n",
       "      <td>152961</td>\n",
       "      <td>393339</td>\n",
       "      <td>73574</td>\n",
       "      <td>236273</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>612664</td>\n",
       "      <td>572756</td>\n",
       "      <td>806109</td>\n",
       "      <td>343719</td>\n",
       "      <td>160457</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>81</td>\n",
       "      <td>43</td>\n",
       "      <td>139872</td>\n",
       "      <td>76161</td>\n",
       "      <td>515730</td>\n",
       "      <td>2460</td>\n",
       "      <td>696074</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>34</td>\n",
       "      <td>1190577</td>\n",
       "      <td>628730</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1385 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender  BMI  Fever  Nausea/Vomting  Headache  Diarrhea  \\\n",
       "0      56       0   35      1               0         0         0   \n",
       "1      46       0   29      0               1         1         0   \n",
       "2      57       0   33      1               1         1         1   \n",
       "3      49       1   33      0               1         0         1   \n",
       "4      59       0   32      0               0         1         0   \n",
       "...   ...     ...  ...    ...             ...       ...       ...   \n",
       "1380   44       0   29      0               1         1         1   \n",
       "1381   55       0   34      0               1         1         0   \n",
       "1382   42       0   26      1               1         0         0   \n",
       "1383   52       0   29      1               0         0         1   \n",
       "1384   55       1   26      0               1         1         1   \n",
       "\n",
       "      Fatigue & generalized bone ache  Jaundice  Epigastric pain  ...  ALT 36  \\\n",
       "0                                   1         1                1  ...       5   \n",
       "1                                   1         1                0  ...      57   \n",
       "2                                   0         0                0  ...       5   \n",
       "3                                   0         1                0  ...      48   \n",
       "4                                   1         1                1  ...      94   \n",
       "...                               ...       ...              ...  ...     ...   \n",
       "1380                                0         0                0  ...      63   \n",
       "1381                                0         0                0  ...      97   \n",
       "1382                                0         1                0  ...      87   \n",
       "1383                                1         1                0  ...      48   \n",
       "1384                                0         1                0  ...      64   \n",
       "\n",
       "      ALT 48  ALT after 24 w  RNA Base   RNA 4   RNA 12  RNA EOT  RNA EF  \\\n",
       "0          5               5    655330  634536   288194        5       5   \n",
       "1        123              44     40620  538635   637056   336804   31085   \n",
       "2          5               5    571148  661346        5   735945  558829   \n",
       "3         77              33   1041941  449939   585688   744463  582301   \n",
       "4         90              30    660410  738756  3731527   338946  242861   \n",
       "...      ...             ...       ...     ...      ...      ...     ...   \n",
       "1380      44              45    387795   55938        5        5       5   \n",
       "1381      64              41    481378  152961   393339    73574  236273   \n",
       "1382      39              24    612664  572756   806109   343719  160457   \n",
       "1383      81              43    139872   76161   515730     2460  696074   \n",
       "1384      71              34   1190577  628730        5        5       5   \n",
       "\n",
       "      Baseline histological Grading  Baselinehistological staging  \n",
       "0                                13                             1  \n",
       "1                                 4                             1  \n",
       "2                                 4                             3  \n",
       "3                                10                             2  \n",
       "4                                11                             0  \n",
       "...                             ...                           ...  \n",
       "1380                             15                             3  \n",
       "1381                             10                             1  \n",
       "1382                              6                             1  \n",
       "1383                             15                             2  \n",
       "1384                             13                             2  \n",
       "\n",
       "[1385 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and preprocess it\n",
    "# https://www.kaggle.com/datasets/brunogrisci/hepatitis-cancer-gene-expression-cumida\n",
    "\n",
    "# Check if stored, otherwise load and store\n",
    "try:\n",
    "    hepatitis = pickle.load(open('data/hepatitis_egypt.pkl', 'rb'))\n",
    "except:\n",
    "    hepatitis = pd.read_csv('data/hepatitis_egypt.csv')\n",
    "    \n",
    "    # Renombrar sin espacios en blanco\n",
    "    hepatitis.columns = [col.rstrip() for col in hepatitis.columns]\n",
    "\n",
    "    # Convertir niveles 1,2 a 0,1\n",
    "    columns_to_map = ['Gender', 'Fever', 'Nausea/Vomting', 'Headache', 'Diarrhea', \n",
    "    'Fatigue & generalized bone ache', 'Jaundice', 'Epigastric pain']\n",
    "    hepatitis[columns_to_map] = hepatitis[columns_to_map]-1\n",
    "    hepatitis['Baselinehistological staging'] = hepatitis['Baselinehistological staging']-1\n",
    "\n",
    "    with open('data/hepatitis_egypt.pkl', 'wb') as f:\n",
    "        pickle.dump(hepatitis, f)\n",
    "        \n",
    "hepatitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in train:\n",
      "3    217\n",
      "2    213\n",
      "0    202\n",
      "1    199\n",
      "Name: Baselinehistological staging, dtype: int64\n",
      "Class distribution in val:\n",
      "3    73\n",
      "2    71\n",
      "0    67\n",
      "1    66\n",
      "Name: Baselinehistological staging, dtype: int64\n",
      "Class distribution in test:\n",
      "3    72\n",
      "2    71\n",
      "1    67\n",
      "0    67\n",
      "Name: Baselinehistological staging, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stratify train-val-test split\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.train_test_split_stratify(df=hepatitis, target='Baselinehistological staging', SEED=1223)\n",
    "\n",
    "# Standardization of continuous variables\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = utils.scale_numerical_variables(X_train, X_test, X_val, \n",
    "                                                                             numerical_variables= [\n",
    "                                                                                \"WBC\", \"RBC\", \"HGB\", \"Plat\", \n",
    "                                                                                \"AST 1\", \"ALT 1\", \"ALT4\", \"ALT 12\", \"ALT 24\", \"ALT 36\", \n",
    "                                                                                \"ALT 48\", \"ALT after 24 w\", \"RNA Base\", \"RNA 4\", \n",
    "                                                                                \"RNA 12\", \"RNA EOT\", \"RNA EF\"\n",
    "                                                                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noselection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 1.9361 - sparse_categorical_accuracy: 0.2671 - val_loss: 1.3883 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3885 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3868 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3866 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3860 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3862 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3856 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3868 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3857 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3865 - sparse_categorical_accuracy: 0.2563 - val_loss: 1.3856 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3874 - sparse_categorical_accuracy: 0.2455 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3859 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3865 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3868 - sparse_categorical_accuracy: 0.2262 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3866 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3866 - sparse_categorical_accuracy: 0.2371 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3867 - sparse_categorical_accuracy: 0.2455 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3865 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3860 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3864 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3862 - sparse_categorical_accuracy: 0.2395 - val_loss: 1.3855 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3872 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.3856 - val_sparse_categorical_accuracy: 0.2635\n"
     ]
    }
   ],
   "source": [
    "model1 = NoSelectionModel(\n",
    "    n_inputs=X_train_scaled.columns.values.shape[0],\n",
    "    n_class=y_train.unique().shape[0]\n",
    ")       \n",
    "\n",
    "model1.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model1.model.save('results/hepatitis_egypt/hepatitis_egypt_NoSelectionModel.h5')\n",
    "with open('results/hepatitis_egypt/hepatitis_egypt_NoSelectionModel_history.pkl', 'wb') as f:\n",
    "    pickle.dump(model1.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 685us/step - loss: 1.3858 - sparse_categorical_accuracy: 0.2599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>1.385829</td>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.107248</td>\n",
       "      <td>28</td>\n",
       "      <td>[Age, Gender, BMI, Fever, Nausea/Vomting, Head...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_loss  test_accuracy   test_f1 number of selected features  \\\n",
       "NoSelection   1.385829       0.259928  0.107248                          28   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [Age, Gender, BMI, Fever, Nausea/Vomting, Head...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose1 = model1.get_verbose()\n",
    "\n",
    "comparative_results.loc['NoSelection'] = [verbose1['results']['loss'], \n",
    "                                          verbose1['results']['accuracy'], \n",
    "                                          verbose1['results']['f1'], \n",
    "                                          verbose1['selected_features'].shape[0], \n",
    "                                          verbose1['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MonoFADL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 1.4539 - sparse_categorical_accuracy: 0.2395 - val_loss: 1.3443 - val_sparse_categorical_accuracy: 0.2383\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.3188 - sparse_categorical_accuracy: 0.2274 - val_loss: 1.2877 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.2590 - sparse_categorical_accuracy: 0.2407 - val_loss: 1.2267 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.1974 - sparse_categorical_accuracy: 0.2587 - val_loss: 1.1641 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.1349 - sparse_categorical_accuracy: 0.2359 - val_loss: 1.1001 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.0692 - sparse_categorical_accuracy: 0.2611 - val_loss: 1.0350 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.0046 - sparse_categorical_accuracy: 0.2419 - val_loss: 0.9693 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9395 - sparse_categorical_accuracy: 0.2503 - val_loss: 0.9029 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8712 - sparse_categorical_accuracy: 0.2659 - val_loss: 0.8359 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8047 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.7686 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7375 - sparse_categorical_accuracy: 0.2202 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6696 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.6331 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6015 - sparse_categorical_accuracy: 0.2383 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5334 - sparse_categorical_accuracy: 0.2407 - val_loss: 0.4966 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4647 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.4280 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3956 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3272 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.2904 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2580 - sparse_categorical_accuracy: 0.2395 - val_loss: 0.2214 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1899 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.1523 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1194 - sparse_categorical_accuracy: 0.2611 - val_loss: 0.0830 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0509 - sparse_categorical_accuracy: 0.2443 - val_loss: 0.0136 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0190 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.0558 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0881 - sparse_categorical_accuracy: 0.2455 - val_loss: -0.1254 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1580 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.1951 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2278 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.2647 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2967 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.3346 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3672 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.4044 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.4373 - sparse_categorical_accuracy: 0.2491 - val_loss: -0.4742 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5071 - sparse_categorical_accuracy: 0.2335 - val_loss: -0.5443 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5771 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.6143 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.6468 - sparse_categorical_accuracy: 0.2611 - val_loss: -0.6844 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7172 - sparse_categorical_accuracy: 0.2455 - val_loss: -0.7545 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7873 - sparse_categorical_accuracy: 0.2563 - val_loss: -0.8247 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8574 - sparse_categorical_accuracy: 0.2383 - val_loss: -0.8949 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9280 - sparse_categorical_accuracy: 0.2455 - val_loss: -0.9653 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9985 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.0356 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0686 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.1061 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.1385 - sparse_categorical_accuracy: 0.2599 - val_loss: -1.1763 - val_sparse_categorical_accuracy: 0.2563\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2090 - sparse_categorical_accuracy: 0.2539 - val_loss: -1.2469 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2800 - sparse_categorical_accuracy: 0.2419 - val_loss: -1.3173 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3507 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.3880 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4213 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.4586 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4909 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.5290 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5622 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.5998 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6331 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.6705 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7036 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.7412 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7741 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.8119 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.8450 - sparse_categorical_accuracy: 0.2335 - val_loss: -1.8827 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9159 - sparse_categorical_accuracy: 0.2611 - val_loss: -1.9536 - val_sparse_categorical_accuracy: 0.2635\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9865 - sparse_categorical_accuracy: 0.2419 - val_loss: -2.0242 - val_sparse_categorical_accuracy: 0.2635\n"
     ]
    }
   ],
   "source": [
    "model2 = MonoFADLModel(\n",
    "    n_inputs=X_train_scaled.columns.values.shape[0],\n",
    "    n_class=y_train.unique().shape[0]\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model2.model.save('results/hepatitis_egypt/hepatitis_egypt_MonoFADLModel.h5')\n",
    "with open('results/hepatitis_egypt/hepatitis_egypt_MonoFADLModel_history.pkl', 'wb') as f:\n",
    "    pickle.dump(model2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 795us/step - loss: -2.0240 - sparse_categorical_accuracy: 0.2599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>1.389501</td>\n",
       "      <td>0.263538</td>\n",
       "      <td>0.120655</td>\n",
       "      <td>28</td>\n",
       "      <td>[Age , Gender, BMI, Fever, Nausea/Vomting, Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>-2.024016</td>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.107248</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_loss  test_accuracy   test_f1 number of selected features  \\\n",
       "NoSelection   1.389501       0.263538  0.120655                          28   \n",
       "MonoFADL     -2.024016       0.259928  0.107248                           0   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [Age , Gender, BMI, Fever, Nausea/Vomting, Hea...  \n",
       "MonoFADL                                                    []  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose2 = model2.get_verbose()\n",
    "\n",
    "comparative_results.loc['MonoFADL'] = [verbose2['results']['loss'], \n",
    "                                          verbose2['results']['accuracy'], \n",
    "                                          verbose2['results']['f1'], \n",
    "                                          verbose2['selected_features'].shape[0], \n",
    "                                          verbose2['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MultiFADL One-versus-Rest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training model class 0 vs rest\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.6179 - binary_accuracy: 0.6775 - val_loss: 0.5179 - val_binary_accuracy: 0.7581\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4868 - binary_accuracy: 0.7569 - val_loss: 0.4531 - val_binary_accuracy: 0.7581\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4276 - binary_accuracy: 0.7569 - val_loss: 0.3986 - val_binary_accuracy: 0.7581\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3761 - binary_accuracy: 0.7569 - val_loss: 0.3477 - val_binary_accuracy: 0.7581\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3255 - binary_accuracy: 0.7569 - val_loss: 0.2974 - val_binary_accuracy: 0.7581\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2755 - binary_accuracy: 0.7569 - val_loss: 0.2452 - val_binary_accuracy: 0.7581\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2221 - binary_accuracy: 0.7569 - val_loss: 0.1936 - val_binary_accuracy: 0.7581\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1712 - binary_accuracy: 0.7569 - val_loss: 0.1396 - val_binary_accuracy: 0.7581\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1222 - binary_accuracy: 0.7569 - val_loss: 0.0853 - val_binary_accuracy: 0.7581\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0601 - binary_accuracy: 0.7569 - val_loss: 0.0300 - val_binary_accuracy: 0.7581\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0056 - binary_accuracy: 0.7569 - val_loss: -0.0258 - val_binary_accuracy: 0.7581\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0502 - binary_accuracy: 0.7569 - val_loss: -0.0826 - val_binary_accuracy: 0.7581\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1076 - binary_accuracy: 0.7569 - val_loss: -0.1403 - val_binary_accuracy: 0.7581\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1640 - binary_accuracy: 0.7569 - val_loss: -0.1965 - val_binary_accuracy: 0.7581\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2222 - binary_accuracy: 0.7569 - val_loss: -0.2559 - val_binary_accuracy: 0.7581\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2821 - binary_accuracy: 0.7569 - val_loss: -0.3147 - val_binary_accuracy: 0.7581\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.3406 - binary_accuracy: 0.7569 - val_loss: -0.3736 - val_binary_accuracy: 0.7581\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.4011 - binary_accuracy: 0.7569 - val_loss: -0.4345 - val_binary_accuracy: 0.7581\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.4586 - binary_accuracy: 0.7569 - val_loss: -0.4895 - val_binary_accuracy: 0.7581\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5205 - binary_accuracy: 0.7569 - val_loss: -0.5554 - val_binary_accuracy: 0.7581\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.5830 - binary_accuracy: 0.7569 - val_loss: -0.6161 - val_binary_accuracy: 0.7581\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.6439 - binary_accuracy: 0.7569 - val_loss: -0.6787 - val_binary_accuracy: 0.7581\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7052 - binary_accuracy: 0.7569 - val_loss: -0.7397 - val_binary_accuracy: 0.7581\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7665 - binary_accuracy: 0.7569 - val_loss: -0.8025 - val_binary_accuracy: 0.7581\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8301 - binary_accuracy: 0.7569 - val_loss: -0.8648 - val_binary_accuracy: 0.7581\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8907 - binary_accuracy: 0.7569 - val_loss: -0.9242 - val_binary_accuracy: 0.7581\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9519 - binary_accuracy: 0.7569 - val_loss: -0.9903 - val_binary_accuracy: 0.7581\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0179 - binary_accuracy: 0.7569 - val_loss: -1.0534 - val_binary_accuracy: 0.7581\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0800 - binary_accuracy: 0.7569 - val_loss: -1.1163 - val_binary_accuracy: 0.7581\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.1447 - binary_accuracy: 0.7569 - val_loss: -1.1800 - val_binary_accuracy: 0.7581\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2068 - binary_accuracy: 0.7569 - val_loss: -1.2408 - val_binary_accuracy: 0.7581\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2700 - binary_accuracy: 0.7569 - val_loss: -1.3068 - val_binary_accuracy: 0.7581\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3362 - binary_accuracy: 0.7569 - val_loss: -1.3717 - val_binary_accuracy: 0.7581\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3995 - binary_accuracy: 0.7569 - val_loss: -1.4359 - val_binary_accuracy: 0.7581\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4634 - binary_accuracy: 0.7569 - val_loss: -1.4994 - val_binary_accuracy: 0.7581\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5283 - binary_accuracy: 0.7569 - val_loss: -1.5642 - val_binary_accuracy: 0.7581\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5942 - binary_accuracy: 0.7569 - val_loss: -1.6289 - val_binary_accuracy: 0.7581\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6586 - binary_accuracy: 0.7569 - val_loss: -1.6945 - val_binary_accuracy: 0.7581\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7231 - binary_accuracy: 0.7569 - val_loss: -1.7595 - val_binary_accuracy: 0.7581\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.7884 - binary_accuracy: 0.7569 - val_loss: -1.8246 - val_binary_accuracy: 0.7581\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.8540 - binary_accuracy: 0.7569 - val_loss: -1.8900 - val_binary_accuracy: 0.7581\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.9191 - binary_accuracy: 0.7569 - val_loss: -1.9554 - val_binary_accuracy: 0.7581\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.9832 - binary_accuracy: 0.7569 - val_loss: -2.0209 - val_binary_accuracy: 0.7581\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.0496 - binary_accuracy: 0.7569 - val_loss: -2.0864 - val_binary_accuracy: 0.7581\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1150 - binary_accuracy: 0.7569 - val_loss: -2.1524 - val_binary_accuracy: 0.7581\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1819 - binary_accuracy: 0.7569 - val_loss: -2.2181 - val_binary_accuracy: 0.7581\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.2471 - binary_accuracy: 0.7569 - val_loss: -2.2841 - val_binary_accuracy: 0.7581\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.3132 - binary_accuracy: 0.7569 - val_loss: -2.3499 - val_binary_accuracy: 0.7581\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.3802 - binary_accuracy: 0.7569 - val_loss: -2.4166 - val_binary_accuracy: 0.7581\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.4458 - binary_accuracy: 0.7569 - val_loss: -2.4831 - val_binary_accuracy: 0.7581\n",
      "--> Training model class 1 vs rest\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.6147 - binary_accuracy: 0.7256 - val_loss: 0.5431 - val_binary_accuracy: 0.7617\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4904 - binary_accuracy: 0.7605 - val_loss: 0.4463 - val_binary_accuracy: 0.7617\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4257 - binary_accuracy: 0.7605 - val_loss: 0.3975 - val_binary_accuracy: 0.7617\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3767 - binary_accuracy: 0.7605 - val_loss: 0.3487 - val_binary_accuracy: 0.7617\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3283 - binary_accuracy: 0.7605 - val_loss: 0.3020 - val_binary_accuracy: 0.7617\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2815 - binary_accuracy: 0.7605 - val_loss: 0.2552 - val_binary_accuracy: 0.7617\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2357 - binary_accuracy: 0.7605 - val_loss: 0.2081 - val_binary_accuracy: 0.7617\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7605 - val_loss: 0.1588 - val_binary_accuracy: 0.7617\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1347 - binary_accuracy: 0.7605 - val_loss: 0.1051 - val_binary_accuracy: 0.7617\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0849 - binary_accuracy: 0.7605 - val_loss: 0.0548 - val_binary_accuracy: 0.7617\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0293 - binary_accuracy: 0.7605 - val_loss: 6.9324e-04 - val_binary_accuracy: 0.7617\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0186 - binary_accuracy: 0.7605 - val_loss: -0.0540 - val_binary_accuracy: 0.7617\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0765 - binary_accuracy: 0.7605 - val_loss: -0.1094 - val_binary_accuracy: 0.7617\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1340 - binary_accuracy: 0.7605 - val_loss: -0.1650 - val_binary_accuracy: 0.7617\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1908 - binary_accuracy: 0.7605 - val_loss: -0.2222 - val_binary_accuracy: 0.7617\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2470 - binary_accuracy: 0.7605 - val_loss: -0.2793 - val_binary_accuracy: 0.7617\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3037 - binary_accuracy: 0.7605 - val_loss: -0.3368 - val_binary_accuracy: 0.7617\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3621 - binary_accuracy: 0.7605 - val_loss: -0.3951 - val_binary_accuracy: 0.7617\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.4213 - binary_accuracy: 0.7605 - val_loss: -0.4544 - val_binary_accuracy: 0.7617\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.4787 - binary_accuracy: 0.7605 - val_loss: -0.5131 - val_binary_accuracy: 0.7617\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5404 - binary_accuracy: 0.7605 - val_loss: -0.5737 - val_binary_accuracy: 0.7617\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5980 - binary_accuracy: 0.7605 - val_loss: -0.6335 - val_binary_accuracy: 0.7617\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.6608 - binary_accuracy: 0.7605 - val_loss: -0.6947 - val_binary_accuracy: 0.7617\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7222 - binary_accuracy: 0.7605 - val_loss: -0.7556 - val_binary_accuracy: 0.7617\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7826 - binary_accuracy: 0.7605 - val_loss: -0.8171 - val_binary_accuracy: 0.7617\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8437 - binary_accuracy: 0.7605 - val_loss: -0.8789 - val_binary_accuracy: 0.7617\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9069 - binary_accuracy: 0.7605 - val_loss: -0.9412 - val_binary_accuracy: 0.7617\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9693 - binary_accuracy: 0.7605 - val_loss: -1.0036 - val_binary_accuracy: 0.7617\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0319 - binary_accuracy: 0.7605 - val_loss: -1.0664 - val_binary_accuracy: 0.7617\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0944 - binary_accuracy: 0.7605 - val_loss: -1.1284 - val_binary_accuracy: 0.7617\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.1574 - binary_accuracy: 0.7605 - val_loss: -1.1924 - val_binary_accuracy: 0.7617\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2212 - binary_accuracy: 0.7605 - val_loss: -1.2564 - val_binary_accuracy: 0.7617\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2846 - binary_accuracy: 0.7605 - val_loss: -1.3202 - val_binary_accuracy: 0.7617\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3490 - binary_accuracy: 0.7605 - val_loss: -1.3843 - val_binary_accuracy: 0.7617\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4119 - binary_accuracy: 0.7605 - val_loss: -1.4485 - val_binary_accuracy: 0.7617\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4772 - binary_accuracy: 0.7605 - val_loss: -1.5128 - val_binary_accuracy: 0.7617\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5425 - binary_accuracy: 0.7605 - val_loss: -1.5777 - val_binary_accuracy: 0.7617\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6059 - binary_accuracy: 0.7605 - val_loss: -1.6429 - val_binary_accuracy: 0.7617\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6683 - binary_accuracy: 0.7605 - val_loss: -1.7081 - val_binary_accuracy: 0.7617\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7365 - binary_accuracy: 0.7605 - val_loss: -1.7727 - val_binary_accuracy: 0.7617\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.8026 - binary_accuracy: 0.7605 - val_loss: -1.8389 - val_binary_accuracy: 0.7617\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.8685 - binary_accuracy: 0.7605 - val_loss: -1.9047 - val_binary_accuracy: 0.7617\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9339 - binary_accuracy: 0.7605 - val_loss: -1.9706 - val_binary_accuracy: 0.7617\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9990 - binary_accuracy: 0.7605 - val_loss: -2.0362 - val_binary_accuracy: 0.7617\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.0667 - binary_accuracy: 0.7605 - val_loss: -2.1026 - val_binary_accuracy: 0.7617\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1320 - binary_accuracy: 0.7605 - val_loss: -2.1694 - val_binary_accuracy: 0.7617\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1983 - binary_accuracy: 0.7605 - val_loss: -2.2353 - val_binary_accuracy: 0.7617\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.2657 - binary_accuracy: 0.7605 - val_loss: -2.3018 - val_binary_accuracy: 0.7617\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.3325 - binary_accuracy: 0.7605 - val_loss: -2.3696 - val_binary_accuracy: 0.7617\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.3995 - binary_accuracy: 0.7605 - val_loss: -2.4363 - val_binary_accuracy: 0.7617\n",
      "--> Training model class 2 vs rest\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.5951 - binary_accuracy: 0.7040 - val_loss: 0.5136 - val_binary_accuracy: 0.7437\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4912 - binary_accuracy: 0.7437 - val_loss: 0.4590 - val_binary_accuracy: 0.7437\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4294 - binary_accuracy: 0.7437 - val_loss: 0.4027 - val_binary_accuracy: 0.7437\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3750 - binary_accuracy: 0.7437 - val_loss: 0.3420 - val_binary_accuracy: 0.7437\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3144 - binary_accuracy: 0.7437 - val_loss: 0.2815 - val_binary_accuracy: 0.7437\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2537 - binary_accuracy: 0.7437 - val_loss: 0.2219 - val_binary_accuracy: 0.7437\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1937 - binary_accuracy: 0.7437 - val_loss: 0.1624 - val_binary_accuracy: 0.7437\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.7437 - val_loss: 0.1033 - val_binary_accuracy: 0.7437\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0742 - binary_accuracy: 0.7437 - val_loss: 0.0385 - val_binary_accuracy: 0.7437\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0090 - binary_accuracy: 0.7437 - val_loss: -0.0240 - val_binary_accuracy: 0.7437\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0528 - binary_accuracy: 0.7437 - val_loss: -0.0862 - val_binary_accuracy: 0.7437\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1164 - binary_accuracy: 0.7437 - val_loss: -0.1502 - val_binary_accuracy: 0.7437\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1819 - binary_accuracy: 0.7437 - val_loss: -0.2156 - val_binary_accuracy: 0.7437\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2453 - binary_accuracy: 0.7437 - val_loss: -0.2795 - val_binary_accuracy: 0.7437\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3105 - binary_accuracy: 0.7437 - val_loss: -0.3457 - val_binary_accuracy: 0.7437\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3766 - binary_accuracy: 0.7437 - val_loss: -0.4113 - val_binary_accuracy: 0.7437\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.4414 - binary_accuracy: 0.7437 - val_loss: -0.4761 - val_binary_accuracy: 0.7437\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5061 - binary_accuracy: 0.7437 - val_loss: -0.5430 - val_binary_accuracy: 0.7437\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5742 - binary_accuracy: 0.7437 - val_loss: -0.6091 - val_binary_accuracy: 0.7437\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.6407 - binary_accuracy: 0.7437 - val_loss: -0.6757 - val_binary_accuracy: 0.7437\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7069 - binary_accuracy: 0.7437 - val_loss: -0.7423 - val_binary_accuracy: 0.7437\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7733 - binary_accuracy: 0.7437 - val_loss: -0.8090 - val_binary_accuracy: 0.7437\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8399 - binary_accuracy: 0.7437 - val_loss: -0.8761 - val_binary_accuracy: 0.7437\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9044 - binary_accuracy: 0.7437 - val_loss: -0.9408 - val_binary_accuracy: 0.7437\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9739 - binary_accuracy: 0.7437 - val_loss: -1.0106 - val_binary_accuracy: 0.7437\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0416 - binary_accuracy: 0.7437 - val_loss: -1.0776 - val_binary_accuracy: 0.7437\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.1083 - binary_accuracy: 0.7437 - val_loss: -1.1451 - val_binary_accuracy: 0.7437\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.1778 - binary_accuracy: 0.7437 - val_loss: -1.2132 - val_binary_accuracy: 0.7437\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2430 - binary_accuracy: 0.7437 - val_loss: -1.2809 - val_binary_accuracy: 0.7437\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3127 - binary_accuracy: 0.7437 - val_loss: -1.3491 - val_binary_accuracy: 0.7437\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.3813 - binary_accuracy: 0.7437 - val_loss: -1.4167 - val_binary_accuracy: 0.7437\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4494 - binary_accuracy: 0.7437 - val_loss: -1.4853 - val_binary_accuracy: 0.7437\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5161 - binary_accuracy: 0.7437 - val_loss: -1.5525 - val_binary_accuracy: 0.7437\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5842 - binary_accuracy: 0.7437 - val_loss: -1.6217 - val_binary_accuracy: 0.7437\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6538 - binary_accuracy: 0.7437 - val_loss: -1.6903 - val_binary_accuracy: 0.7437\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7228 - binary_accuracy: 0.7437 - val_loss: -1.7588 - val_binary_accuracy: 0.7437\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7900 - binary_accuracy: 0.7437 - val_loss: -1.8274 - val_binary_accuracy: 0.7437\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.8570 - binary_accuracy: 0.7437 - val_loss: -1.8946 - val_binary_accuracy: 0.7437\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9288 - binary_accuracy: 0.7437 - val_loss: -1.9646 - val_binary_accuracy: 0.7437\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9964 - binary_accuracy: 0.7437 - val_loss: -2.0328 - val_binary_accuracy: 0.7437\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.0660 - binary_accuracy: 0.7437 - val_loss: -2.1022 - val_binary_accuracy: 0.7437\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1346 - binary_accuracy: 0.7437 - val_loss: -2.1711 - val_binary_accuracy: 0.7437\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.2026 - binary_accuracy: 0.7437 - val_loss: -2.2400 - val_binary_accuracy: 0.7437\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -2.2715 - binary_accuracy: 0.7437 - val_loss: -2.3090 - val_binary_accuracy: 0.7437\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.3415 - binary_accuracy: 0.7437 - val_loss: -2.3779 - val_binary_accuracy: 0.7437\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.4102 - binary_accuracy: 0.7437 - val_loss: -2.4472 - val_binary_accuracy: 0.7437\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.4791 - binary_accuracy: 0.7437 - val_loss: -2.5152 - val_binary_accuracy: 0.7437\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.5479 - binary_accuracy: 0.7437 - val_loss: -2.5857 - val_binary_accuracy: 0.7437\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.6179 - binary_accuracy: 0.7437 - val_loss: -2.6549 - val_binary_accuracy: 0.7437\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.6875 - binary_accuracy: 0.7437 - val_loss: -2.7243 - val_binary_accuracy: 0.7437\n",
      "--> Training model class 3 vs rest\n",
      "Epoch 1/50\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.6917 - binary_accuracy: 0.5788 - val_loss: 0.6108 - val_binary_accuracy: 0.7365\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5606 - binary_accuracy: 0.7389 - val_loss: 0.5097 - val_binary_accuracy: 0.7365\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4654 - binary_accuracy: 0.7389 - val_loss: 0.4221 - val_binary_accuracy: 0.7365\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3822 - binary_accuracy: 0.7389 - val_loss: 0.3432 - val_binary_accuracy: 0.7365\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3057 - binary_accuracy: 0.7389 - val_loss: 0.2707 - val_binary_accuracy: 0.7365\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2339 - binary_accuracy: 0.7389 - val_loss: 0.1997 - val_binary_accuracy: 0.7365\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1643 - binary_accuracy: 0.7389 - val_loss: 0.1304 - val_binary_accuracy: 0.7365\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0953 - binary_accuracy: 0.7389 - val_loss: 0.0619 - val_binary_accuracy: 0.7365\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0266 - binary_accuracy: 0.7389 - val_loss: -0.0066 - val_binary_accuracy: 0.7365\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.0419 - binary_accuracy: 0.7389 - val_loss: -0.0753 - val_binary_accuracy: 0.7365\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1105 - binary_accuracy: 0.7389 - val_loss: -0.1441 - val_binary_accuracy: 0.7365\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.1795 - binary_accuracy: 0.7389 - val_loss: -0.2130 - val_binary_accuracy: 0.7365\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.2484 - binary_accuracy: 0.7389 - val_loss: -0.2822 - val_binary_accuracy: 0.7365\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3176 - binary_accuracy: 0.7389 - val_loss: -0.3514 - val_binary_accuracy: 0.7365\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.3870 - binary_accuracy: 0.7389 - val_loss: -0.4208 - val_binary_accuracy: 0.7365\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.4567 - binary_accuracy: 0.7389 - val_loss: -0.4903 - val_binary_accuracy: 0.7365\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -0.5261 - binary_accuracy: 0.7389 - val_loss: -0.5599 - val_binary_accuracy: 0.7365\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.5958 - binary_accuracy: 0.7389 - val_loss: -0.6296 - val_binary_accuracy: 0.7365\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.6654 - binary_accuracy: 0.7389 - val_loss: -0.6994 - val_binary_accuracy: 0.7365\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.7354 - binary_accuracy: 0.7389 - val_loss: -0.7693 - val_binary_accuracy: 0.7365\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8052 - binary_accuracy: 0.7389 - val_loss: -0.8392 - val_binary_accuracy: 0.7365\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.8752 - binary_accuracy: 0.7389 - val_loss: -0.9093 - val_binary_accuracy: 0.7365\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -0.9452 - binary_accuracy: 0.7389 - val_loss: -0.9794 - val_binary_accuracy: 0.7365\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0155 - binary_accuracy: 0.7389 - val_loss: -1.0495 - val_binary_accuracy: 0.7365\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.0857 - binary_accuracy: 0.7389 - val_loss: -1.1197 - val_binary_accuracy: 0.7365\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.1555 - binary_accuracy: 0.7389 - val_loss: -1.1900 - val_binary_accuracy: 0.7365\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.2261 - binary_accuracy: 0.7389 - val_loss: -1.2603 - val_binary_accuracy: 0.7365\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.2965 - binary_accuracy: 0.7389 - val_loss: -1.3306 - val_binary_accuracy: 0.7365\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.3668 - binary_accuracy: 0.7389 - val_loss: -1.4011 - val_binary_accuracy: 0.7365\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.4373 - binary_accuracy: 0.7389 - val_loss: -1.4715 - val_binary_accuracy: 0.7365\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.5076 - binary_accuracy: 0.7389 - val_loss: -1.5421 - val_binary_accuracy: 0.7365\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -1.5783 - binary_accuracy: 0.7389 - val_loss: -1.6126 - val_binary_accuracy: 0.7365\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.6489 - binary_accuracy: 0.7389 - val_loss: -1.6832 - val_binary_accuracy: 0.7365\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7192 - binary_accuracy: 0.7389 - val_loss: -1.7537 - val_binary_accuracy: 0.7365\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.7902 - binary_accuracy: 0.7389 - val_loss: -1.8245 - val_binary_accuracy: 0.7365\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.8609 - binary_accuracy: 0.7389 - val_loss: -1.8952 - val_binary_accuracy: 0.7365\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -1.9315 - binary_accuracy: 0.7389 - val_loss: -1.9659 - val_binary_accuracy: 0.7365\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.0022 - binary_accuracy: 0.7389 - val_loss: -2.0367 - val_binary_accuracy: 0.7365\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.0729 - binary_accuracy: 0.7389 - val_loss: -2.1075 - val_binary_accuracy: 0.7365\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.1439 - binary_accuracy: 0.7389 - val_loss: -2.1783 - val_binary_accuracy: 0.7365\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.2147 - binary_accuracy: 0.7389 - val_loss: -2.2492 - val_binary_accuracy: 0.7365\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.2857 - binary_accuracy: 0.7389 - val_loss: -2.3201 - val_binary_accuracy: 0.7365\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -2.3563 - binary_accuracy: 0.7389 - val_loss: -2.3910 - val_binary_accuracy: 0.7365\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.4275 - binary_accuracy: 0.7389 - val_loss: -2.4620 - val_binary_accuracy: 0.7365\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.4985 - binary_accuracy: 0.7389 - val_loss: -2.5330 - val_binary_accuracy: 0.7365\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -2.5694 - binary_accuracy: 0.7389 - val_loss: -2.6040 - val_binary_accuracy: 0.7365\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.6404 - binary_accuracy: 0.7389 - val_loss: -2.6750 - val_binary_accuracy: 0.7365\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.7115 - binary_accuracy: 0.7389 - val_loss: -2.7461 - val_binary_accuracy: 0.7365\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 0s 1ms/step - loss: -2.7826 - binary_accuracy: 0.7389 - val_loss: -2.8172 - val_binary_accuracy: 0.7365\n",
      "Epoch 50/50\n",
      "26/26 [==============================] - 0s 2ms/step - loss: -2.8536 - binary_accuracy: 0.7389 - val_loss: -2.8883 - val_binary_accuracy: 0.7365\n"
     ]
    }
   ],
   "source": [
    "model3 = MultiFADLModelOvR(\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "for clas, model in model3.models.items():\n",
    "    model.model.save(f'results/hepatitis_egypt/hepatitis_egypt_MultiFADLModel_{clas}.h5')    \n",
    "    with open(f'results/hepatitis_egypt/hepatitis_egypt_MultiFADLModel_history_{clas}.pkl', 'wb') as f:\n",
    "        pickle.dump(model.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Evaluating model class 0 vs rest\n",
      "9/9 [==============================] - 0s 686us/step - loss: -2.4831 - binary_accuracy: 0.7581\n",
      "{'loss': -2.4830527305603027, 'accuracy': 0.7581227421760559, 'f1': 0.6538224894180089}\n",
      "--> Evaluating model class 1 vs rest\n",
      "9/9 [==============================] - 0s 654us/step - loss: -2.4323 - binary_accuracy: 0.7581\n",
      "{'loss': -2.432304859161377, 'accuracy': 0.7581227421760559, 'f1': 0.6538224894180089}\n",
      "--> Evaluating model class 2 vs rest\n",
      "9/9 [==============================] - 0s 673us/step - loss: -2.7243 - binary_accuracy: 0.7437\n",
      "{'loss': -2.724271774291992, 'accuracy': 0.743682324886322, 'f1': 0.6343625505452535}\n",
      "--> Evaluating model class 3 vs rest\n",
      "9/9 [==============================] - 0s 706us/step - loss: -2.8921 - binary_accuracy: 0.7401\n",
      "{'loss': -2.892096996307373, 'accuracy': 0.7400721907615662, 'f1': 0.6295219976931259}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>1.3895</td>\n",
       "      <td>0.263538</td>\n",
       "      <td>0.120655</td>\n",
       "      <td>28</td>\n",
       "      <td>[Age , Gender, BMI, Fever, Nausea/Vomting, Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>-2.02402</td>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.107248</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiFADL</th>\n",
       "      <td>{0: -2.4830527305603027, 1: -2.432304859161377...</td>\n",
       "      <td>{0: 0.7581227421760559, 1: 0.7581227421760559,...</td>\n",
       "      <td>{0: 0.6538224894180089, 1: 0.6538224894180089,...</td>\n",
       "      <td>{0: 0, 1: 0, 2: 0, 3: 0, 'global': 0}</td>\n",
       "      <td>{0: [], 1: [], 2: [], 3: [], 'global': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     test_loss  \\\n",
       "NoSelection                                             1.3895   \n",
       "MonoFADL                                              -2.02402   \n",
       "MultiFADL    {0: -2.4830527305603027, 1: -2.432304859161377...   \n",
       "\n",
       "                                                 test_accuracy  \\\n",
       "NoSelection                                           0.263538   \n",
       "MonoFADL                                              0.259928   \n",
       "MultiFADL    {0: 0.7581227421760559, 1: 0.7581227421760559,...   \n",
       "\n",
       "                                                       test_f1  \\\n",
       "NoSelection                                           0.120655   \n",
       "MonoFADL                                              0.107248   \n",
       "MultiFADL    {0: 0.6538224894180089, 1: 0.6538224894180089,...   \n",
       "\n",
       "                       number of selected features  \\\n",
       "NoSelection                                     28   \n",
       "MonoFADL                                         0   \n",
       "MultiFADL    {0: 0, 1: 0, 2: 0, 3: 0, 'global': 0}   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [Age , Gender, BMI, Fever, Nausea/Vomting, Hea...  \n",
       "MonoFADL                                                    []  \n",
       "MultiFADL           {0: [], 1: [], 2: [], 3: [], 'global': []}  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose3 = model3.get_verbose()\n",
    "\n",
    "comparative_results.loc['MultiFADL'] = [verbose3['results']['loss'], \n",
    "                                          verbose3['results']['accuracy'], \n",
    "                                          verbose3['results']['f1'], \n",
    "                                          {clas: verbose3['selected_features'][clas].shape[0] for clas in verbose3['selected_features']}, \n",
    "                                          verbose3['selected_features']]\n",
    "\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results.to_csv('results/hepatitis_egypt/hepatitis_egypt_ComparativeResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
