{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas MultiFADL One-versus-Rest. fetal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src import utils\n",
    "\n",
    "from src.MonoFADLModel import MonoFADLModel\n",
    "from src.MultiFADLModelOvR import MultiFADLModelOvR\n",
    "from src.NoSelectionModel import NoSelectionModel\n",
    "\n",
    "# Seed for neural network executions\n",
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results = pd.DataFrame(columns=['test_loss', 'test_accuracy', 'test_f1', 'number of selected features', 'selected Features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>...</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "      <th>fetal_health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "0              120.0          0.000           0.000                 0.000   \n",
       "1              132.0          0.006           0.000                 0.006   \n",
       "2              133.0          0.003           0.000                 0.008   \n",
       "3              134.0          0.003           0.000                 0.008   \n",
       "4              132.0          0.007           0.000                 0.008   \n",
       "...              ...            ...             ...                   ...   \n",
       "2121           140.0          0.000           0.000                 0.007   \n",
       "2122           140.0          0.001           0.000                 0.007   \n",
       "2123           140.0          0.001           0.000                 0.007   \n",
       "2124           140.0          0.001           0.000                 0.006   \n",
       "2125           142.0          0.002           0.002                 0.008   \n",
       "\n",
       "      light_decelerations  prolongued_decelerations  \\\n",
       "0                   0.000                       0.0   \n",
       "1                   0.003                       0.0   \n",
       "2                   0.003                       0.0   \n",
       "3                   0.003                       0.0   \n",
       "4                   0.000                       0.0   \n",
       "...                   ...                       ...   \n",
       "2121                0.000                       0.0   \n",
       "2122                0.000                       0.0   \n",
       "2123                0.000                       0.0   \n",
       "2124                0.000                       0.0   \n",
       "2125                0.000                       0.0   \n",
       "\n",
       "      abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "0                                73.0                                   0.5   \n",
       "1                                17.0                                   2.1   \n",
       "2                                16.0                                   2.1   \n",
       "3                                16.0                                   2.4   \n",
       "4                                16.0                                   2.4   \n",
       "...                               ...                                   ...   \n",
       "2121                             79.0                                   0.2   \n",
       "2122                             78.0                                   0.4   \n",
       "2123                             79.0                                   0.4   \n",
       "2124                             78.0                                   0.4   \n",
       "2125                             74.0                                   0.4   \n",
       "\n",
       "      percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "0                                                  43.0        \n",
       "1                                                   0.0        \n",
       "2                                                   0.0        \n",
       "3                                                   0.0        \n",
       "4                                                   0.0        \n",
       "...                                                 ...        \n",
       "2121                                               25.0        \n",
       "2122                                               22.0        \n",
       "2123                                               20.0        \n",
       "2124                                               27.0        \n",
       "2125                                               36.0        \n",
       "\n",
       "      mean_value_of_long_term_variability  ...  histogram_min  histogram_max  \\\n",
       "0                                     2.4  ...           62.0          126.0   \n",
       "1                                    10.4  ...           68.0          198.0   \n",
       "2                                    13.4  ...           68.0          198.0   \n",
       "3                                    23.0  ...           53.0          170.0   \n",
       "4                                    19.9  ...           53.0          170.0   \n",
       "...                                   ...  ...            ...            ...   \n",
       "2121                                  7.2  ...          137.0          177.0   \n",
       "2122                                  7.1  ...          103.0          169.0   \n",
       "2123                                  6.1  ...          103.0          170.0   \n",
       "2124                                  7.0  ...          103.0          169.0   \n",
       "2125                                  5.0  ...          117.0          159.0   \n",
       "\n",
       "      histogram_number_of_peaks  histogram_number_of_zeroes  histogram_mode  \\\n",
       "0                           2.0                         0.0           120.0   \n",
       "1                           6.0                         1.0           141.0   \n",
       "2                           5.0                         1.0           141.0   \n",
       "3                          11.0                         0.0           137.0   \n",
       "4                           9.0                         0.0           137.0   \n",
       "...                         ...                         ...             ...   \n",
       "2121                        4.0                         0.0           153.0   \n",
       "2122                        6.0                         0.0           152.0   \n",
       "2123                        5.0                         0.0           153.0   \n",
       "2124                        6.0                         0.0           152.0   \n",
       "2125                        2.0                         1.0           145.0   \n",
       "\n",
       "      histogram_mean  histogram_median  histogram_variance  \\\n",
       "0              137.0             121.0                73.0   \n",
       "1              136.0             140.0                12.0   \n",
       "2              135.0             138.0                13.0   \n",
       "3              134.0             137.0                13.0   \n",
       "4              136.0             138.0                11.0   \n",
       "...              ...               ...                 ...   \n",
       "2121           150.0             152.0                 2.0   \n",
       "2122           148.0             151.0                 3.0   \n",
       "2123           148.0             152.0                 4.0   \n",
       "2124           147.0             151.0                 4.0   \n",
       "2125           143.0             145.0                 1.0   \n",
       "\n",
       "      histogram_tendency  fetal_health  \n",
       "0                    1.0           1.0  \n",
       "1                    0.0           0.0  \n",
       "2                    0.0           0.0  \n",
       "3                    1.0           0.0  \n",
       "4                    1.0           0.0  \n",
       "...                  ...           ...  \n",
       "2121                 0.0           1.0  \n",
       "2122                 1.0           1.0  \n",
       "2123                 1.0           1.0  \n",
       "2124                 1.0           1.0  \n",
       "2125                 0.0           0.0  \n",
       "\n",
       "[2126 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and preprocess it\n",
    "# https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification\n",
    "\n",
    "# Check if stored, otherwise load and store\n",
    "try:\n",
    "    fetal = pickle.load(open('data/fetal_health.pkl', 'rb'))\n",
    "except:\n",
    "    fetal = pd.read_csv('data/fetal_health.csv')\n",
    "    fetal = fetal.drop(['severe_decelerations'], axis=1)\n",
    "    fetal['fetal_health'] = fetal['fetal_health']-1\n",
    "    \n",
    "    with open('data/fetal_health.pkl', 'wb') as f:\n",
    "        pickle.dump(fetal, f)\n",
    "        \n",
    "fetal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in train:\n",
      "0.0    1167\n",
      "1.0     208\n",
      "2.0     124\n",
      "Name: fetal_health, dtype: int64\n",
      "Class distribution in val:\n",
      "0.0    240\n",
      "1.0     43\n",
      "2.0     25\n",
      "Name: fetal_health, dtype: int64\n",
      "Class distribution in test:\n",
      "0.0    248\n",
      "1.0     44\n",
      "2.0     27\n",
      "Name: fetal_health, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Stratify train-val-test split\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.train_test_split_stratify(df=fetal, target='fetal_health', SEED=1223)\n",
    "\n",
    "# Standardization of continuous variables\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = utils.scale_numerical_variables(X_train, X_test, X_val, numerical_variables=X_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline value</th>\n",
       "      <th>accelerations</th>\n",
       "      <th>fetal_movement</th>\n",
       "      <th>uterine_contractions</th>\n",
       "      <th>light_decelerations</th>\n",
       "      <th>prolongued_decelerations</th>\n",
       "      <th>abnormal_short_term_variability</th>\n",
       "      <th>mean_value_of_short_term_variability</th>\n",
       "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
       "      <th>mean_value_of_long_term_variability</th>\n",
       "      <th>histogram_width</th>\n",
       "      <th>histogram_min</th>\n",
       "      <th>histogram_max</th>\n",
       "      <th>histogram_number_of_peaks</th>\n",
       "      <th>histogram_number_of_zeroes</th>\n",
       "      <th>histogram_mode</th>\n",
       "      <th>histogram_mean</th>\n",
       "      <th>histogram_median</th>\n",
       "      <th>histogram_variance</th>\n",
       "      <th>histogram_tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.082569</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.338290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112426</td>\n",
       "      <td>0.361582</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258383</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.513761</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.577982</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.096647</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.926606</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.788991</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.477064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.581921</td>\n",
       "      <td>0.045872</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.385321</td>\n",
       "      <td>0.282528</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.494505</td>\n",
       "      <td>0.216963</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236686</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.146789</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.645669</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.614679</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.209040</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1499 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      baseline value  accelerations  fetal_movement  uterine_contractions  \\\n",
       "975         0.462963       0.000000        0.000000              0.357143   \n",
       "1383        0.277778       0.000000        0.000000              0.571429   \n",
       "1365        0.481481       0.000000        0.000000              0.285714   \n",
       "1461        0.777778       0.000000        0.000000              0.357143   \n",
       "1664        0.000000       0.000000        0.000000              0.642857   \n",
       "...              ...            ...             ...                   ...   \n",
       "1881        0.592593       0.000000        0.004158              0.714286   \n",
       "310         0.740741       0.000000        0.012474              0.000000   \n",
       "1670        0.074074       0.000000        0.000000              0.357143   \n",
       "1827        0.629630       0.000000        0.002079              0.142857   \n",
       "1251        0.111111       0.166667        0.000000              0.285714   \n",
       "\n",
       "      light_decelerations  prolongued_decelerations  \\\n",
       "975              0.466667                       0.0   \n",
       "1383             0.533333                       0.0   \n",
       "1365             0.000000                       0.0   \n",
       "1461             0.000000                       0.0   \n",
       "1664             0.000000                       0.0   \n",
       "...                   ...                       ...   \n",
       "1881             0.800000                       0.4   \n",
       "310              0.000000                       0.0   \n",
       "1670             0.000000                       0.0   \n",
       "1827             0.533333                       0.0   \n",
       "1251             0.000000                       0.0   \n",
       "\n",
       "      abnormal_short_term_variability  mean_value_of_short_term_variability  \\\n",
       "975                          0.270270                              0.294118   \n",
       "1383                         0.216216                              0.176471   \n",
       "1365                         0.148649                              0.191176   \n",
       "1461                         0.513514                              0.044118   \n",
       "1664                         0.702703                              0.058824   \n",
       "...                               ...                                   ...   \n",
       "1881                         0.621622                              0.338235   \n",
       "310                          0.770270                              0.044118   \n",
       "1670                         0.702703                              0.058824   \n",
       "1827                         0.662162                              0.161765   \n",
       "1251                         0.162162                              0.161765   \n",
       "\n",
       "      percentage_of_time_with_abnormal_long_term_variability  \\\n",
       "975                                            0.131868        \n",
       "1383                                           0.000000        \n",
       "1365                                           0.000000        \n",
       "1461                                           0.659341        \n",
       "1664                                           0.000000        \n",
       "...                                                 ...        \n",
       "1881                                           0.000000        \n",
       "310                                            0.494505        \n",
       "1670                                           0.000000        \n",
       "1827                                           0.000000        \n",
       "1251                                           0.087912        \n",
       "\n",
       "      mean_value_of_long_term_variability  histogram_width  histogram_min  \\\n",
       "975                              0.120316         0.593220       0.082569   \n",
       "1383                             0.112426         0.361582       0.183486   \n",
       "1365                             0.258383         0.220339       0.513761   \n",
       "1461                             0.096647         0.050847       0.926606   \n",
       "1664                             0.205128         0.096045       0.477064   \n",
       "...                                   ...              ...            ...   \n",
       "1881                             0.023669         0.581921       0.045872   \n",
       "310                              0.216963         0.220339       0.614679   \n",
       "1670                             0.236686         0.152542       0.440367   \n",
       "1827                             0.076923         0.508475       0.146789   \n",
       "1251                             0.205128         0.209040       0.495413   \n",
       "\n",
       "      histogram_max  histogram_number_of_peaks  histogram_number_of_zeroes  \\\n",
       "975        0.387931                     0.3750                         0.1   \n",
       "1383       0.129310                     0.1250                         0.1   \n",
       "1365       0.224138                     0.3125                         0.0   \n",
       "1461       0.353448                     0.0625                         0.0   \n",
       "1664       0.000000                     0.0625                         0.0   \n",
       "...             ...                        ...                         ...   \n",
       "1881       0.336207                     0.5000                         0.1   \n",
       "310        0.318966                     0.3750                         0.0   \n",
       "1670       0.051724                     0.0625                         0.0   \n",
       "1827       0.318966                     0.4375                         0.1   \n",
       "1251       0.189655                     0.0000                         0.1   \n",
       "\n",
       "      histogram_mode  histogram_mean  histogram_median  histogram_variance  \\\n",
       "975         0.653543        0.477064          0.550459            0.338290   \n",
       "1383        0.425197        0.357798          0.357798            0.078067   \n",
       "1365        0.614173        0.577982          0.559633            0.011152   \n",
       "1461        0.787402        0.788991          0.761468            0.000000   \n",
       "1664        0.401575        0.348624          0.321101            0.000000   \n",
       "...              ...             ...               ...                 ...   \n",
       "1881        0.448819        0.275229          0.385321            0.282528   \n",
       "310         0.732283        0.706422          0.688073            0.011152   \n",
       "1670        0.393701        0.348624          0.321101            0.003717   \n",
       "1827        0.645669        0.568807          0.614679            0.089219   \n",
       "1251        0.425197        0.376147          0.339450            0.011152   \n",
       "\n",
       "      histogram_tendency  \n",
       "975                  1.0  \n",
       "1383                 1.0  \n",
       "1365                 1.0  \n",
       "1461                 1.0  \n",
       "1664                 0.5  \n",
       "...                  ...  \n",
       "1881                 0.5  \n",
       "310                  1.0  \n",
       "1670                 0.5  \n",
       "1827                 1.0  \n",
       "1251                 0.0  \n",
       "\n",
       "[1499 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Noselection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.5661 - sparse_categorical_accuracy: 0.7792 - val_loss: 0.4020 - val_sparse_categorical_accuracy: 0.8149\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3518 - sparse_categorical_accuracy: 0.8466 - val_loss: 0.3497 - val_sparse_categorical_accuracy: 0.8442\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.8632 - val_loss: 0.3194 - val_sparse_categorical_accuracy: 0.8474\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 998us/step - loss: 0.2912 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.3277 - val_sparse_categorical_accuracy: 0.8734\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 999us/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.2881 - val_sparse_categorical_accuracy: 0.8571\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 977us/step - loss: 0.2618 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.2571 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 984us/step - loss: 0.2474 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.2480 - val_sparse_categorical_accuracy: 0.9058\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 971us/step - loss: 0.2345 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.2406 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2234 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.2367 - val_sparse_categorical_accuracy: 0.9026\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.2416 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2281 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2262 - val_sparse_categorical_accuracy: 0.8961\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 969us/step - loss: 0.2112 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.2446 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 987us/step - loss: 0.2154 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.2419 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 974us/step - loss: 0.2081 - sparse_categorical_accuracy: 0.9066 - val_loss: 0.2724 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 994us/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9086 - val_loss: 0.2300 - val_sparse_categorical_accuracy: 0.9058\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 996us/step - loss: 0.2098 - sparse_categorical_accuracy: 0.9079 - val_loss: 0.2362 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2094 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.2311 - val_sparse_categorical_accuracy: 0.8961\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1924 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.8831\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 994us/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9126 - val_loss: 0.2357 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1890 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.8961\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 988us/step - loss: 0.1963 - sparse_categorical_accuracy: 0.9019 - val_loss: 0.2539 - val_sparse_categorical_accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "model1 = NoSelectionModel(\n",
    "    n_inputs=X_train_scaled.columns.values.shape[0],\n",
    "    n_class=y_train.unique().shape[0]\n",
    ")       \n",
    "\n",
    "model1.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model1.model.save('results/fetal_health/fetal_health_NoSelectionModel.h5')\n",
    "with open('results/fetal_health/fetal_health_NoSelectionModel_history.pkl', 'wb') as f:\n",
    "    pickle.dump(model1.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 645us/step - loss: 0.2322 - sparse_categorical_accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.232203</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>20</td>\n",
       "      <td>[baseline value, accelerations, fetal_movement...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_loss  test_accuracy   test_f1 number of selected features  \\\n",
       "NoSelection   0.232203       0.884013  0.880543                          20   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [baseline value, accelerations, fetal_movement...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose1 = model1.get_verbose()\n",
    "\n",
    "comparative_results.loc['NoSelection'] = [verbose1['results']['loss'], \n",
    "                                          verbose1['results']['accuracy'], \n",
    "                                          verbose1['results']['f1'], \n",
    "                                          verbose1['selected_features'].shape[0], \n",
    "                                          verbose1['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MonoFADL results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.5369 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4745 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.4455 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4059 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.3891 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3501 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2957 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.2747 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2335 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.2116 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1794 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1141 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.0855 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.0344 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0173 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.0501 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0839 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.1102 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.1626 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.1926 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2272 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.2615 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2946 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.3392 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.3815 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.3964 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4463 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.4843 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.5256 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.5638 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.5933 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.6408 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.6830 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.7172 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.7523 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.7936 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 998us/step - loss: -0.8356 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.8707 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 989us/step - loss: -0.9064 - sparse_categorical_accuracy: 0.7785 - val_loss: -0.9405 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.9958 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.0251 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 994us/step - loss: -1.0695 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.1092 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.1448 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.1907 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.2307 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.2625 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3085 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.3523 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3824 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.4237 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.4751 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.4958 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.5482 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.5947 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.6324 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.6697 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 995us/step - loss: -1.7152 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.7600 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 998us/step - loss: -1.7971 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.8423 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.8856 - sparse_categorical_accuracy: 0.7785 - val_loss: -1.9268 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9643 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.0112 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.0477 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.0937 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.1243 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.1774 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.2231 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.2553 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.2896 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.3440 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.3936 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.4292 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.4700 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.5146 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.5521 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.5923 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.6388 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.6865 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.7296 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.5258 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.8118 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.8541 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.8912 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.9416 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.9879 - sparse_categorical_accuracy: 0.7785 - val_loss: -2.8185 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.0670 - sparse_categorical_accuracy: 0.7785 - val_loss: -3.1106 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.1595 - sparse_categorical_accuracy: 0.7785 - val_loss: -3.1995 - val_sparse_categorical_accuracy: 0.7792\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.2432 - sparse_categorical_accuracy: 0.7785 - val_loss: -3.2854 - val_sparse_categorical_accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "model2 = MonoFADLModel(\n",
    "    n_inputs=X_train_scaled.columns.values.shape[0],\n",
    "    n_class=y_train.unique().shape[0]\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "model2.model.save('results/fetal_health/fetal_health_MonoFADLModel.h5')\n",
    "with open('results/fetal_health/fetal_health_MonoFADLModel_history.pkl', 'wb') as f:\n",
    "    pickle.dump(model2.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 717us/step - loss: -3.3122 - sparse_categorical_accuracy: 0.7774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.232203</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>20</td>\n",
       "      <td>[baseline value, accelerations, fetal_movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>-3.312196</td>\n",
       "      <td>0.777429</td>\n",
       "      <td>0.680079</td>\n",
       "      <td>1</td>\n",
       "      <td>[accelerations]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             test_loss  test_accuracy   test_f1 number of selected features  \\\n",
       "NoSelection   0.232203       0.884013  0.880543                          20   \n",
       "MonoFADL     -3.312196       0.777429  0.680079                           1   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [baseline value, accelerations, fetal_movement...  \n",
       "MonoFADL                                       [accelerations]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose2 = model2.get_verbose()\n",
    "\n",
    "comparative_results.loc['MonoFADL'] = [verbose2['results']['loss'], \n",
    "                                          verbose2['results']['accuracy'], \n",
    "                                          verbose2['results']['f1'], \n",
    "                                          verbose2['selected_features'].shape[0], \n",
    "                                          verbose2['selected_features']]\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3558778e-01, 1.6687723e-01, 9.7534947e-02],\n",
       "       [9.8716563e-01, 5.8426135e-03, 6.9916393e-03],\n",
       "       [9.9769717e-01, 7.8001496e-04, 1.5228052e-03],\n",
       "       [9.3376172e-01, 3.8164821e-02, 2.8073439e-02],\n",
       "       [5.8649307e-01, 2.6079828e-01, 1.5270860e-01],\n",
       "       [9.9769717e-01, 7.8001496e-04, 1.5228052e-03],\n",
       "       [8.4939921e-01, 9.5860809e-02, 5.4739941e-02],\n",
       "       [9.9769717e-01, 7.8001496e-04, 1.5228052e-03],\n",
       "       [5.8649307e-01, 2.6079828e-01, 1.5270860e-01],\n",
       "       [5.8649307e-01, 2.6079828e-01, 1.5270860e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose2['predictionsproba'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MultiFADL One-versus-Rest results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training model class 0.0 vs rest\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.5196 - binary_accuracy: 0.7645 - val_loss: 0.4676 - val_binary_accuracy: 0.7792\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.4262 - binary_accuracy: 0.7785 - val_loss: 0.3836 - val_binary_accuracy: 0.7792\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.3448 - binary_accuracy: 0.7785 - val_loss: 0.3036 - val_binary_accuracy: 0.7792\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2639 - binary_accuracy: 0.7785 - val_loss: 0.2210 - val_binary_accuracy: 0.7792\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1803 - binary_accuracy: 0.7785 - val_loss: 0.1329 - val_binary_accuracy: 0.7792\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0915 - binary_accuracy: 0.7785 - val_loss: 0.0449 - val_binary_accuracy: 0.7792\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0041 - binary_accuracy: 0.7785 - val_loss: -0.0413 - val_binary_accuracy: 0.7792\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0846 - binary_accuracy: 0.7785 - val_loss: -0.1311 - val_binary_accuracy: 0.7792\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.1743 - binary_accuracy: 0.7785 - val_loss: -0.2188 - val_binary_accuracy: 0.7792\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2623 - binary_accuracy: 0.7785 - val_loss: -0.3109 - val_binary_accuracy: 0.7792\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.3523 - binary_accuracy: 0.7785 - val_loss: -0.4001 - val_binary_accuracy: 0.7792\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4418 - binary_accuracy: 0.7785 - val_loss: -0.4911 - val_binary_accuracy: 0.7792\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.5322 - binary_accuracy: 0.7785 - val_loss: -0.5808 - val_binary_accuracy: 0.7792\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.6232 - binary_accuracy: 0.7785 - val_loss: -0.6717 - val_binary_accuracy: 0.7792\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.7139 - binary_accuracy: 0.7785 - val_loss: -0.7569 - val_binary_accuracy: 0.7792\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.8038 - binary_accuracy: 0.7785 - val_loss: -0.8535 - val_binary_accuracy: 0.7792\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.8957 - binary_accuracy: 0.7785 - val_loss: -0.9437 - val_binary_accuracy: 0.7792\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.9863 - binary_accuracy: 0.7785 - val_loss: -1.0358 - val_binary_accuracy: 0.7792\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.0784 - binary_accuracy: 0.7785 - val_loss: -1.1267 - val_binary_accuracy: 0.7792\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.1687 - binary_accuracy: 0.7785 - val_loss: -1.2168 - val_binary_accuracy: 0.7792\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.2614 - binary_accuracy: 0.7785 - val_loss: -1.3101 - val_binary_accuracy: 0.7792\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3522 - binary_accuracy: 0.7785 - val_loss: -1.4014 - val_binary_accuracy: 0.7792\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.4450 - binary_accuracy: 0.7785 - val_loss: -1.4938 - val_binary_accuracy: 0.7792\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.5361 - binary_accuracy: 0.7785 - val_loss: -1.5846 - val_binary_accuracy: 0.7792\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.6288 - binary_accuracy: 0.7785 - val_loss: -1.6758 - val_binary_accuracy: 0.7792\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.7203 - binary_accuracy: 0.7785 - val_loss: -1.7700 - val_binary_accuracy: 0.7792\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.8132 - binary_accuracy: 0.7785 - val_loss: -1.8621 - val_binary_accuracy: 0.7792\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9049 - binary_accuracy: 0.7785 - val_loss: -1.9538 - val_binary_accuracy: 0.7792\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9967 - binary_accuracy: 0.7785 - val_loss: -2.0440 - val_binary_accuracy: 0.7792\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.0879 - binary_accuracy: 0.7785 - val_loss: -2.1387 - val_binary_accuracy: 0.7792\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.1826 - binary_accuracy: 0.7785 - val_loss: -2.2317 - val_binary_accuracy: 0.7792\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.2753 - binary_accuracy: 0.7785 - val_loss: -2.3242 - val_binary_accuracy: 0.7792\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.3678 - binary_accuracy: 0.7785 - val_loss: -2.4174 - val_binary_accuracy: 0.7792\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.4610 - binary_accuracy: 0.7785 - val_loss: -2.5098 - val_binary_accuracy: 0.7792\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.5541 - binary_accuracy: 0.7785 - val_loss: -2.6026 - val_binary_accuracy: 0.7792\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.6467 - binary_accuracy: 0.7785 - val_loss: -2.6946 - val_binary_accuracy: 0.7792\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.7394 - binary_accuracy: 0.7785 - val_loss: -2.7883 - val_binary_accuracy: 0.7792\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.8326 - binary_accuracy: 0.7785 - val_loss: -2.8818 - val_binary_accuracy: 0.7792\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.9256 - binary_accuracy: 0.7785 - val_loss: -2.9749 - val_binary_accuracy: 0.7792\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.0164 - binary_accuracy: 0.7785 - val_loss: -3.0655 - val_binary_accuracy: 0.7792\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.1115 - binary_accuracy: 0.7785 - val_loss: -3.1609 - val_binary_accuracy: 0.7792\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.2033 - binary_accuracy: 0.7785 - val_loss: -3.2543 - val_binary_accuracy: 0.7792\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.2983 - binary_accuracy: 0.7785 - val_loss: -3.3462 - val_binary_accuracy: 0.7792\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.3902 - binary_accuracy: 0.7785 - val_loss: -3.4407 - val_binary_accuracy: 0.7792\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.4849 - binary_accuracy: 0.7785 - val_loss: -3.5330 - val_binary_accuracy: 0.7792\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.5774 - binary_accuracy: 0.7785 - val_loss: -3.6263 - val_binary_accuracy: 0.7792\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.6708 - binary_accuracy: 0.7785 - val_loss: -3.7202 - val_binary_accuracy: 0.7792\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.7645 - binary_accuracy: 0.7785 - val_loss: -3.8140 - val_binary_accuracy: 0.7792\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.8583 - binary_accuracy: 0.7785 - val_loss: -3.9073 - val_binary_accuracy: 0.7792\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.9512 - binary_accuracy: 0.7785 - val_loss: -4.0009 - val_binary_accuracy: 0.7792\n",
      "--> Training model class 1.0 vs rest\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.4225 - binary_accuracy: 0.8459 - val_loss: 0.3318 - val_binary_accuracy: 0.8604\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2936 - binary_accuracy: 0.8612 - val_loss: 0.2556 - val_binary_accuracy: 0.8604\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.2137 - binary_accuracy: 0.8612 - val_loss: 0.1776 - val_binary_accuracy: 0.8604\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1303 - binary_accuracy: 0.8612 - val_loss: 0.0876 - val_binary_accuracy: 0.8604\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0458 - binary_accuracy: 0.8612 - val_loss: -7.9629e-04 - val_binary_accuracy: 0.8604\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0451 - binary_accuracy: 0.8612 - val_loss: -0.0902 - val_binary_accuracy: 0.8604\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.1329 - binary_accuracy: 0.8612 - val_loss: -0.1787 - val_binary_accuracy: 0.8604\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2220 - binary_accuracy: 0.8612 - val_loss: -0.2636 - val_binary_accuracy: 0.8604\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.3097 - binary_accuracy: 0.8612 - val_loss: -0.3557 - val_binary_accuracy: 0.8604\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.3999 - binary_accuracy: 0.8612 - val_loss: -0.4455 - val_binary_accuracy: 0.8604\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4872 - binary_accuracy: 0.8612 - val_loss: -0.5339 - val_binary_accuracy: 0.8604\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.5800 - binary_accuracy: 0.8612 - val_loss: -0.6237 - val_binary_accuracy: 0.8604\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.6658 - binary_accuracy: 0.8612 - val_loss: -0.7130 - val_binary_accuracy: 0.8604\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.7567 - binary_accuracy: 0.8612 - val_loss: -0.8047 - val_binary_accuracy: 0.8604\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.8506 - binary_accuracy: 0.8612 - val_loss: -0.8901 - val_binary_accuracy: 0.8604\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.9360 - binary_accuracy: 0.8612 - val_loss: -0.9853 - val_binary_accuracy: 0.8604\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.0292 - binary_accuracy: 0.8612 - val_loss: -1.0758 - val_binary_accuracy: 0.8604\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.1192 - binary_accuracy: 0.8612 - val_loss: -1.1619 - val_binary_accuracy: 0.8604\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.2099 - binary_accuracy: 0.8612 - val_loss: -1.2583 - val_binary_accuracy: 0.8604\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3023 - binary_accuracy: 0.8612 - val_loss: -1.3444 - val_binary_accuracy: 0.8604\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3935 - binary_accuracy: 0.8612 - val_loss: -1.4406 - val_binary_accuracy: 0.8604\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.4863 - binary_accuracy: 0.8612 - val_loss: -1.5318 - val_binary_accuracy: 0.8604\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.5778 - binary_accuracy: 0.8612 - val_loss: -1.6234 - val_binary_accuracy: 0.8604\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.6695 - binary_accuracy: 0.8612 - val_loss: -1.7150 - val_binary_accuracy: 0.8604\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.7602 - binary_accuracy: 0.8612 - val_loss: -1.8069 - val_binary_accuracy: 0.8604\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.8518 - binary_accuracy: 0.8612 - val_loss: -1.8997 - val_binary_accuracy: 0.8604\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9446 - binary_accuracy: 0.8612 - val_loss: -1.9911 - val_binary_accuracy: 0.8604\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.0366 - binary_accuracy: 0.8612 - val_loss: -2.0835 - val_binary_accuracy: 0.8604\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.1277 - binary_accuracy: 0.8612 - val_loss: -2.1706 - val_binary_accuracy: 0.8604\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.2168 - binary_accuracy: 0.8612 - val_loss: -2.2683 - val_binary_accuracy: 0.8604\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.3127 - binary_accuracy: 0.8612 - val_loss: -2.3607 - val_binary_accuracy: 0.8604\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.4065 - binary_accuracy: 0.8612 - val_loss: -2.4535 - val_binary_accuracy: 0.8604\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.4981 - binary_accuracy: 0.8612 - val_loss: -2.5457 - val_binary_accuracy: 0.8604\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.5922 - binary_accuracy: 0.8612 - val_loss: -2.6381 - val_binary_accuracy: 0.8604\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.6846 - binary_accuracy: 0.8612 - val_loss: -2.7301 - val_binary_accuracy: 0.8604\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.7768 - binary_accuracy: 0.8612 - val_loss: -2.8232 - val_binary_accuracy: 0.8604\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.8694 - binary_accuracy: 0.8612 - val_loss: -2.9165 - val_binary_accuracy: 0.8604\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.9627 - binary_accuracy: 0.8612 - val_loss: -3.0102 - val_binary_accuracy: 0.8604\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.0555 - binary_accuracy: 0.8612 - val_loss: -3.1030 - val_binary_accuracy: 0.8604\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.1474 - binary_accuracy: 0.8612 - val_loss: -3.1954 - val_binary_accuracy: 0.8604\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.2415 - binary_accuracy: 0.8612 - val_loss: -3.2892 - val_binary_accuracy: 0.8604\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.3333 - binary_accuracy: 0.8612 - val_loss: -3.3811 - val_binary_accuracy: 0.8604\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.4278 - binary_accuracy: 0.8612 - val_loss: -3.4743 - val_binary_accuracy: 0.8604\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.5201 - binary_accuracy: 0.8612 - val_loss: -3.5687 - val_binary_accuracy: 0.8604\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.6155 - binary_accuracy: 0.8612 - val_loss: -3.6609 - val_binary_accuracy: 0.8604\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.7075 - binary_accuracy: 0.8612 - val_loss: -3.7547 - val_binary_accuracy: 0.8604\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.8015 - binary_accuracy: 0.8612 - val_loss: -3.8484 - val_binary_accuracy: 0.8604\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.8946 - binary_accuracy: 0.8612 - val_loss: -3.9418 - val_binary_accuracy: 0.8604\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.9881 - binary_accuracy: 0.8612 - val_loss: -4.0331 - val_binary_accuracy: 0.8604\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -4.0803 - binary_accuracy: 0.8612 - val_loss: -4.1282 - val_binary_accuracy: 0.8604\n",
      "--> Training model class 2.0 vs rest\n",
      "Epoch 1/50\n",
      "47/47 [==============================] - 1s 4ms/step - loss: 0.2466 - binary_accuracy: 0.9179 - val_loss: 0.1671 - val_binary_accuracy: 0.9188\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.1267 - binary_accuracy: 0.9173 - val_loss: 0.0935 - val_binary_accuracy: 0.9188\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.0287 - binary_accuracy: 0.9173 - val_loss: 0.0023 - val_binary_accuracy: 0.9188\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0672 - binary_accuracy: 0.9400 - val_loss: -0.0850 - val_binary_accuracy: 0.9286\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.0774 - binary_accuracy: 0.9153 - val_loss: -0.1708 - val_binary_accuracy: 0.9318\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2402 - binary_accuracy: 0.9520 - val_loss: -0.2455 - val_binary_accuracy: 0.9318\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.3211 - binary_accuracy: 0.9546 - val_loss: -0.3292 - val_binary_accuracy: 0.9318\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.2202 - binary_accuracy: 0.8112 - val_loss: -0.3943 - val_binary_accuracy: 0.9188\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4603 - binary_accuracy: 0.9173 - val_loss: -0.4756 - val_binary_accuracy: 0.9188\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4538 - binary_accuracy: 0.8833 - val_loss: -0.2635 - val_binary_accuracy: 0.9188\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.4234 - binary_accuracy: 0.9173 - val_loss: -0.5296 - val_binary_accuracy: 0.9188\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.5920 - binary_accuracy: 0.9173 - val_loss: -0.6536 - val_binary_accuracy: 0.9188\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.7000 - binary_accuracy: 0.9173 - val_loss: -0.7523 - val_binary_accuracy: 0.9188\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.7933 - binary_accuracy: 0.9173 - val_loss: -0.8422 - val_binary_accuracy: 0.9188\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.8814 - binary_accuracy: 0.9173 - val_loss: -0.9292 - val_binary_accuracy: 0.9188\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -0.9676 - binary_accuracy: 0.9173 - val_loss: -1.0148 - val_binary_accuracy: 0.9188\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.0529 - binary_accuracy: 0.9173 - val_loss: -1.1002 - val_binary_accuracy: 0.9188\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.1380 - binary_accuracy: 0.9173 - val_loss: -1.1852 - val_binary_accuracy: 0.9188\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.2232 - binary_accuracy: 0.9173 - val_loss: -1.2705 - val_binary_accuracy: 0.9188\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3084 - binary_accuracy: 0.9173 - val_loss: -1.3558 - val_binary_accuracy: 0.9188\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.3938 - binary_accuracy: 0.9173 - val_loss: -1.4413 - val_binary_accuracy: 0.9188\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.4793 - binary_accuracy: 0.9173 - val_loss: -1.5270 - val_binary_accuracy: 0.9188\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.5651 - binary_accuracy: 0.9173 - val_loss: -1.6129 - val_binary_accuracy: 0.9188\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.6510 - binary_accuracy: 0.9173 - val_loss: -1.6989 - val_binary_accuracy: 0.9188\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.7372 - binary_accuracy: 0.9173 - val_loss: -1.7851 - val_binary_accuracy: 0.9188\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.8235 - binary_accuracy: 0.9173 - val_loss: -1.8715 - val_binary_accuracy: 0.9188\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9100 - binary_accuracy: 0.9173 - val_loss: -1.9581 - val_binary_accuracy: 0.9188\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -1.9966 - binary_accuracy: 0.9173 - val_loss: -2.0449 - val_binary_accuracy: 0.9188\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.0834 - binary_accuracy: 0.9173 - val_loss: -2.1318 - val_binary_accuracy: 0.9188\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.1704 - binary_accuracy: 0.9173 - val_loss: -2.2188 - val_binary_accuracy: 0.9188\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.2576 - binary_accuracy: 0.9173 - val_loss: -2.3061 - val_binary_accuracy: 0.9188\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.3449 - binary_accuracy: 0.9173 - val_loss: -2.3935 - val_binary_accuracy: 0.9188\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.4324 - binary_accuracy: 0.9173 - val_loss: -2.4810 - val_binary_accuracy: 0.9188\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.5200 - binary_accuracy: 0.9173 - val_loss: -2.5687 - val_binary_accuracy: 0.9188\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.6077 - binary_accuracy: 0.9173 - val_loss: -2.6565 - val_binary_accuracy: 0.9188\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.6956 - binary_accuracy: 0.9173 - val_loss: -2.7445 - val_binary_accuracy: 0.9188\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.7836 - binary_accuracy: 0.9173 - val_loss: -2.8326 - val_binary_accuracy: 0.9188\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.8718 - binary_accuracy: 0.9173 - val_loss: -2.9208 - val_binary_accuracy: 0.9188\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -2.9601 - binary_accuracy: 0.9173 - val_loss: -3.0092 - val_binary_accuracy: 0.9188\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.0485 - binary_accuracy: 0.9173 - val_loss: -3.0976 - val_binary_accuracy: 0.9188\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.1370 - binary_accuracy: 0.9173 - val_loss: -3.1862 - val_binary_accuracy: 0.9188\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.2257 - binary_accuracy: 0.9173 - val_loss: -3.2750 - val_binary_accuracy: 0.9188\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.3145 - binary_accuracy: 0.9173 - val_loss: -3.3639 - val_binary_accuracy: 0.9188\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.4034 - binary_accuracy: 0.9173 - val_loss: -3.4529 - val_binary_accuracy: 0.9188\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.4924 - binary_accuracy: 0.9173 - val_loss: -3.5419 - val_binary_accuracy: 0.9188\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.5816 - binary_accuracy: 0.9173 - val_loss: -3.6312 - val_binary_accuracy: 0.9188\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.6707 - binary_accuracy: 0.9173 - val_loss: -3.7205 - val_binary_accuracy: 0.9188\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.7603 - binary_accuracy: 0.9173 - val_loss: -3.8099 - val_binary_accuracy: 0.9188\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.8496 - binary_accuracy: 0.9173 - val_loss: -3.8994 - val_binary_accuracy: 0.9188\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 0s 1ms/step - loss: -3.9393 - binary_accuracy: 0.9173 - val_loss: -3.9891 - val_binary_accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "model3 = MultiFADLModelOvR(\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_val_scaled,\n",
    "    y_val,\n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "for clas, model in model3.models.items():\n",
    "    model.model.save(f'results/fetal_health/fetal_health_MultiFADLModel_{clas}.h5')    \n",
    "    with open(f'results/fetal_health/fetal_health_MultiFADLModel_history_{clas}.pkl', 'wb') as f:\n",
    "        pickle.dump(model.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Evaluating model class 0.0 vs rest\n",
      "10/10 [==============================] - 0s 1ms/step - loss: -3.9986 - binary_accuracy: 0.7774\n",
      "{'loss': -3.9985787868499756, 'accuracy': 0.777429461479187, 'f1': 0.08103850172815691}\n",
      "--> Evaluating model class 1.0 vs rest\n",
      "10/10 [==============================] - 0s 691us/step - loss: -4.1314 - binary_accuracy: 0.8621\n",
      "{'loss': -4.131368160247803, 'accuracy': 0.8620689511299133, 'f1': 0.7982120051085568}\n",
      "--> Evaluating model class 2.0 vs rest\n",
      "10/10 [==============================] - 0s 693us/step - loss: -3.9807 - binary_accuracy: 0.9154\n",
      "{'loss': -3.980703353881836, 'accuracy': 0.9153605103492737, 'f1': 0.8749108558352873}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>number of selected features</th>\n",
       "      <th>selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoSelection</th>\n",
       "      <td>0.232203</td>\n",
       "      <td>0.884013</td>\n",
       "      <td>0.880543</td>\n",
       "      <td>20</td>\n",
       "      <td>[baseline value, accelerations, fetal_movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonoFADL</th>\n",
       "      <td>-3.3122</td>\n",
       "      <td>0.777429</td>\n",
       "      <td>0.680079</td>\n",
       "      <td>1</td>\n",
       "      <td>[accelerations]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiFADL</th>\n",
       "      <td>{0.0: -3.9985787868499756, 1.0: -4.13136816024...</td>\n",
       "      <td>{0.0: 0.777429461479187, 1.0: 0.86206895112991...</td>\n",
       "      <td>{0.0: 0.08103850172815691, 1.0: 0.798212005108...</td>\n",
       "      <td>{0.0: 0, 1.0: 0, 2.0: 0, 'global': 0}</td>\n",
       "      <td>{0.0: [], 1.0: [], 2.0: [], 'global': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     test_loss  \\\n",
       "NoSelection                                           0.232203   \n",
       "MonoFADL                                               -3.3122   \n",
       "MultiFADL    {0.0: -3.9985787868499756, 1.0: -4.13136816024...   \n",
       "\n",
       "                                                 test_accuracy  \\\n",
       "NoSelection                                           0.884013   \n",
       "MonoFADL                                              0.777429   \n",
       "MultiFADL    {0.0: 0.777429461479187, 1.0: 0.86206895112991...   \n",
       "\n",
       "                                                       test_f1  \\\n",
       "NoSelection                                           0.880543   \n",
       "MonoFADL                                              0.680079   \n",
       "MultiFADL    {0.0: 0.08103850172815691, 1.0: 0.798212005108...   \n",
       "\n",
       "                       number of selected features  \\\n",
       "NoSelection                                     20   \n",
       "MonoFADL                                         1   \n",
       "MultiFADL    {0.0: 0, 1.0: 0, 2.0: 0, 'global': 0}   \n",
       "\n",
       "                                             selected Features  \n",
       "NoSelection  [baseline value, accelerations, fetal_movement...  \n",
       "MonoFADL                                       [accelerations]  \n",
       "MultiFADL            {0.0: [], 1.0: [], 2.0: [], 'global': []}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "verbose3 = model3.get_verbose()\n",
    "\n",
    "comparative_results.loc['MultiFADL'] = [verbose3['results']['loss'], \n",
    "                                          verbose3['results']['accuracy'], \n",
    "                                          verbose3['results']['f1'], \n",
    "                                          {clas: verbose3['selected_features'][clas].shape[0] for clas in verbose3['selected_features']}, \n",
    "                                          verbose3['selected_features']]\n",
    "\n",
    "comparative_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_results.to_csv('results/fetal_health/fetal_health_ComparativeResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: [[0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]\n",
      " [0.7804307]]\n",
      "1.0: [[0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]\n",
      " [0.1294443]]\n",
      "2.0: [[0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]\n",
      " [0.08220246]]\n",
      "global: [[0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]\n",
      " [0.7804307  0.1294443  0.08220246]]\n"
     ]
    }
   ],
   "source": [
    "for clase, probs in verbose3['predictionsproba'].items():\n",
    "    print(f'{clase}: {probs[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
